{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d042d2b8",
   "metadata": {
    "id": "d042d2b8"
   },
   "source": [
    "<h1 style=\"color:rgb(0,120,170)\">MLPC Assignment 3: Classification</h1>\n",
    "\n",
    "<h3 style=\"color:rgb(0,120,170)\">Context</h3>\n",
    "\n",
    "Turning this into a machine learning problem entails:\n",
    "1. splitting up the audio into small fragments, which will become the training examples,\n",
    "2. computing a set of audio features for each fragment,\n",
    "3. assigning a label to each fragment,\n",
    "4. training a classifier to predict the label from the audio features.\n",
    "\n",
    "<h3 style=\"color:rgb(0,120,170)\">Context</h3>\n",
    "Using the same training data as in Task 2, perform systematic classification experiments\n",
    "in your team:\n",
    "\n",
    "• Focus on predicting the presence or absence of the 6 bird species. Remember that\n",
    "we made the simplifying assumption that these species will never be audible at\n",
    "the same time, so for each audio fragment, there are exactly 7 options: either one\n",
    "of the 6 species is audible, or none of them.\n",
    "\n",
    "• Decide on an evaluation criterion to use. Mind that your goal is to correctly recognize all the birds.\n",
    "\n",
    "• Apply at least least four different learning algorithms, from different major groups:\n",
    "Support Vector Machines, Neural Networks, Nearest Neighbor Classifiers, Naive\n",
    "Bayes, Decision Trees, Generalized Linear Models, Linear and Quadratic Discriminant Analysis. . . maybe also an “ensemble method” such as a Random Forest.\n",
    "\n",
    "• For each algorithm, perform a systematic evaluation of different parameter settings, especially for those parameters that control the algorithm’s overfitting behavior. Analyse and document how the parameters affect whether overfitting\n",
    "occurs (and to what extend it occurs), and how they affect classification performance.\n",
    "\n",
    "• Use cross-validation for all your experiments. Decide how to split up the data\n",
    "into folds, based on what you know about the data. Mind that your goal is to\n",
    "estimate how your classifier will perform on unseen bird recordings.\n",
    "For these experiments, you may use any machine learning package you want, such as\n",
    "scikit-learn for Python, WEKA for Java, or builtin toolboxes for Matlab. You may want\n",
    "to exploit that neither all the features nor all the training examples are equally useful.\n",
    "Especially when working on (not-so-powerful) laptops, it can pay off to subsample the\n",
    "training data to save computation time.\n",
    "\n",
    "Document your results in a slide deck, touching each of the following aspects:\n",
    "\n",
    "1. Data split: How was the cross-validation split done, and why?\n",
    "\n",
    "2. Features: Which subset of features was selected or which preprocessing was applied, and why?\n",
    "\n",
    "3. Evaluation: Which evaluation criterion did you choose to compare parameter\n",
    "settings and algorithms? What is the baseline performance, what is the best we\n",
    "can expect?\n",
    "4. Experiments: For at least four different classifiers from the major groups given\n",
    "above, vary the parameters, focusing on: (a) Does overfitting occur, to what extent, and what does it depend on? (b) How does classification performance change?\n",
    "Include visualizations and/or tables to present your results. Compile a slide deck of\n",
    "at most 20 slides (plus a title slide that includes your team name and member names).\n",
    "Make sure to address all four aspects in your report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff652b79",
   "metadata": {
    "id": "ff652b79"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "from scipy import signal\n",
    "import os\n",
    "import glob\n",
    "\n",
    "from sklearn.decomposition import PCA, FastICA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, mutual_info_classif\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c3d0f1b",
   "metadata": {
    "id": "8c3d0f1b"
   },
   "source": [
    "<h3 style=\"color:rgb(0,120,170)\">1. Data Loading</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "FKIT_oT6gX7K",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FKIT_oT6gX7K",
    "outputId": "c683bb8e-891c-4870-a5b8-98c921330584"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/72/k144hg1s1bl5jf6b4jqxr8zw0000gn/T/ipykernel_31881/907070862.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google'"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "F1rCXiKHIEOf",
   "metadata": {
    "id": "F1rCXiKHIEOf"
   },
   "source": [
    "<h3 style=\"color:rgb(0,120,170)\">1.1. File Path</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d22894d5",
   "metadata": {
    "id": "d22894d5"
   },
   "outputs": [],
   "source": [
    "#1. Loading data\n",
    "def get_all_files(directory_path):\n",
    "    # Get a list of all the files in the directory\n",
    "    file_names = os.listdir(directory_path)\n",
    "    file_paths = [os.path.join(directory_path, file_name) for file_name in file_names if '.DS_Store' not in file_name]\n",
    "    file_paths = [file_path for file_path in file_paths if os.path.isfile(file_path)]\n",
    "    return file_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8367f78c",
   "metadata": {
    "id": "8367f78c"
   },
   "outputs": [],
   "source": [
    "#2. Labeling (1 to six for target birds and 0 for no bird, e.g.)\n",
    "root_dir = \"/Users/luizhmadjarof/Documents/Universidade/(23:-) AI JKU Linz/SS 23 (1S)/MLPC MA/UB/A2/python\"\n",
    "feature_names = np.loadtxt(\"/Users/luizhmadjarof/Documents/Universidade/(23:-) AI JKU Linz/SS 23 (1S)/MLPC MA/UB/A2/python/feature_names.txt\", dtype=str).T\n",
    "\n",
    "dir_cowpig1 = root_dir + '/' + 'cowpig1'\n",
    "dir_eueowl1= root_dir + '/' + 'eueowl1'\n",
    "dir_tawowl1= root_dir + '/' + 'tawowl1'\n",
    "dir_eucdov= root_dir + '/' + 'eucdov'\n",
    "dir_grswoo= root_dir + '/' + 'grswoo'\n",
    "dir_comcuc= root_dir + '/' + 'comcuc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5f1ea602",
   "metadata": {
    "id": "5f1ea602"
   },
   "outputs": [],
   "source": [
    "files_cowpig1= get_all_files(dir_cowpig1)\n",
    "files_eueowl1= get_all_files(dir_eueowl1)\n",
    "files_tawowl1= get_all_files(dir_tawowl1)\n",
    "files_eucdov= get_all_files(dir_eucdov)\n",
    "files_grswoo= get_all_files(dir_grswoo)\n",
    "files_comcuc= get_all_files(dir_comcuc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "DwognB9wNlIG",
   "metadata": {
    "id": "DwognB9wNlIG"
   },
   "source": [
    "<h3 style=\"color:rgb(0,120,170)\">1.2. Label Data Loading</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6b6dc5ad",
   "metadata": {
    "id": "6b6dc5ad"
   },
   "outputs": [],
   "source": [
    "all_cowpig1 = np.empty((0, 8))\n",
    "all_eueowl1 = np.empty((0, 8))\n",
    "all_tawowl1= np.empty((0, 8))\n",
    "all_eucdov= np.empty((0, 8))\n",
    "all_grswoo= np.empty((0, 8))\n",
    "all_comcuc= np.empty((0, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "834c6d89",
   "metadata": {
    "id": "834c6d89"
   },
   "outputs": [],
   "source": [
    "# Create an empty dictionary to store the label data\n",
    "all_data = {}\n",
    "\n",
    "# Loop through the files for each label\n",
    "for label, files in {'cowpig1': files_cowpig1, \n",
    "                     'eueowl1': files_eueowl1, \n",
    "                     'tawowl1': files_tawowl1, \n",
    "                     'eucdov': files_eucdov, \n",
    "                     'grswoo': files_grswoo, \n",
    "                     'comcuc': files_comcuc}.items():\n",
    "    # Initialize an empty list to store the individual data arrays for this label\n",
    "    arrays = []\n",
    "    \n",
    "    # Loop through the files for this label\n",
    "    for file in files:\n",
    "        a,b = os.path.splitext(file)\n",
    "        if a.endswith(\".labels\"):\n",
    "            # Load the data array for this file\n",
    "            array = np.load(file)\n",
    "            # Append it to the list of arrays for this label\n",
    "            arrays.append(array)\n",
    "    \n",
    "    # Determine the maximum number of columns across all arrays for this label\n",
    "    max_columns = max(array.shape[1] for array in arrays)\n",
    "    \n",
    "    # Initialize an empty list to store the padded arrays for this label\n",
    "    padded_arrays = []\n",
    "    # Loop through each array for this label\n",
    "    for array in arrays:\n",
    "        # If the array has fewer columns than the maximum, pad it with zeros\n",
    "        if array.shape[1] < max_columns:\n",
    "            num_columns_to_add = max_columns - array.shape[1]\n",
    "            padding = np.zeros((array.shape[0], num_columns_to_add))\n",
    "            padded_array = np.concatenate((array, padding), axis=1)\n",
    "            padded_arrays.append(padded_array)\n",
    "        else:\n",
    "            # Otherwise, append the array unchanged\n",
    "            padded_arrays.append(array)\n",
    "    \n",
    "    # Concatenate the padded arrays along the first axis (rows) to create the final data array for this label\n",
    "    all_data[label] = np.concatenate(padded_arrays, axis=0)\n",
    "\n",
    "# Now you can access the final concatenated and padded data for each label using the dictionary\n",
    "all_cowpig1 = all_data['cowpig1']\n",
    "all_eueowl1 = all_data['eueowl1']\n",
    "all_tawowl1 = all_data['tawowl1']\n",
    "all_eucdov = all_data['eucdov']\n",
    "all_grswoo = all_data['grswoo']\n",
    "all_comcuc = all_data['comcuc']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d2b0de0f",
   "metadata": {
    "id": "d2b0de0f"
   },
   "outputs": [],
   "source": [
    "all_files = np.concatenate((all_cowpig1, all_eueowl1, all_tawowl1, all_eucdov, all_grswoo, all_comcuc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "77c2fe83",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "77c2fe83",
    "outputId": "3651c7c0-d973-49b7-c882-7b432d6cc6ac"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119995</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119996</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119997</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119998</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119999</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120000 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0    1    2    3    4    5    6    7\n",
       "0       0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "1       0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "2       0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "3       0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "4       0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "...     ...  ...  ...  ...  ...  ...  ...  ...\n",
       "119995  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "119996  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "119997  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "119998  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "119999  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "\n",
       "[120000 rows x 8 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = pd.DataFrame(all_files)\n",
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "WgewK-AuKZGU",
   "metadata": {
    "id": "WgewK-AuKZGU"
   },
   "source": [
    "<h3 style=\"color:rgb(0,120,170)\">1.2. Feature Data Loading</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c2675e72",
   "metadata": {
    "id": "c2675e72"
   },
   "outputs": [],
   "source": [
    "#Feature data\n",
    "all_fcowpig1 = np.empty((0, 548))\n",
    "all_feueowl1 = np.empty((0, 548))\n",
    "all_ftawowl1= np.empty((0, 548))\n",
    "all_feucdov= np.empty((0, 548))\n",
    "all_fgrswoo= np.empty((0, 548))\n",
    "all_fcomcuc= np.empty((0, 548))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "65bZY1eTL29s",
   "metadata": {
    "id": "65bZY1eTL29s"
   },
   "outputs": [],
   "source": [
    "# Create an empty dictionary to store the label data\n",
    "all_fdata = {}\n",
    "\n",
    "# Loop through the files for each label\n",
    "for label, files in {'cowpig1': files_cowpig1, \n",
    "                     'eueowl1': files_eueowl1, \n",
    "                     'tawowl1': files_tawowl1, \n",
    "                     'eucdov': files_eucdov, \n",
    "                     'grswoo': files_grswoo, \n",
    "                     'comcuc': files_comcuc}.items():\n",
    "    # Initialize an empty list to store the individual data arrays for this label\n",
    "    arrays = []\n",
    "    \n",
    "    # Loop through the files for this label\n",
    "    for file in files:\n",
    "        a,b = os.path.splitext(file)\n",
    "        if not a.endswith(\".labels\"):\n",
    "            # Load the data array for this file\n",
    "            array = np.load(file)\n",
    "            # Append it to the list of arrays for this label\n",
    "            arrays.append(array)\n",
    "    \n",
    "    # Determine the maximum number of columns across all arrays for this label\n",
    "    max_columns = max(array.shape[1] for array in arrays)\n",
    "    \n",
    "    # Initialize an empty list to store the padded arrays for this label\n",
    "    padded_arrays = []\n",
    "    # Loop through each array for this label\n",
    "    for array in arrays:\n",
    "        # If the array has fewer columns than the maximum, pad it with zeros\n",
    "        if array.shape[1] < max_columns:\n",
    "            num_columns_to_add = max_columns - array.shape[1]\n",
    "            padding = np.zeros((array.shape[0], num_columns_to_add))\n",
    "            padded_array = np.concatenate((array, padding), axis=1)\n",
    "            padded_arrays.append(padded_array)\n",
    "        else:\n",
    "            # Otherwise, append the array unchanged\n",
    "            padded_arrays.append(array)\n",
    "    \n",
    "    # Concatenate the padded arrays along the first axis (rows) to create the final data array for this label\n",
    "    all_fdata[label] = np.concatenate(padded_arrays, axis=0)\n",
    "\n",
    "# Now you can access the final concatenated and padded data for each label using the dictionary\n",
    "all_fcowpig1 = all_fdata['cowpig1']\n",
    "all_feueowl1 = all_fdata['eueowl1']\n",
    "all_ftawowl1 = all_fdata['tawowl1']\n",
    "all_feucdov = all_fdata['eucdov']\n",
    "all_fgrswoo = all_fdata['grswoo']\n",
    "all_fcomcuc = all_fdata['comcuc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "be51691b",
   "metadata": {
    "id": "be51691b"
   },
   "outputs": [],
   "source": [
    "all_ffiles = np.concatenate((all_fcowpig1, all_feueowl1, all_ftawowl1, all_feucdov, all_fgrswoo, all_fcomcuc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5b4530a2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "id": "5b4530a2",
    "outputId": "7739b6c4-7dee-4453-f9f4-3bca5ccc24df"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>zcr_mean</th>\n",
       "      <th>zcr_std</th>\n",
       "      <th>yin_0</th>\n",
       "      <th>yin_1</th>\n",
       "      <th>yin_2</th>\n",
       "      <th>yin_3</th>\n",
       "      <th>yin_4</th>\n",
       "      <th>yin_5</th>\n",
       "      <th>yin_6</th>\n",
       "      <th>yin_7</th>\n",
       "      <th>...</th>\n",
       "      <th>cln_contrast_mean_4</th>\n",
       "      <th>cln_contrast_mean_5</th>\n",
       "      <th>cln_contrast_mean_6</th>\n",
       "      <th>cln_contrast_std_0</th>\n",
       "      <th>cln_contrast_std_1</th>\n",
       "      <th>cln_contrast_std_2</th>\n",
       "      <th>cln_contrast_std_3</th>\n",
       "      <th>cln_contrast_std_4</th>\n",
       "      <th>cln_contrast_std_5</th>\n",
       "      <th>cln_contrast_std_6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.104213</td>\n",
       "      <td>0.025389</td>\n",
       "      <td>144.178635</td>\n",
       "      <td>167.021698</td>\n",
       "      <td>115.430466</td>\n",
       "      <td>115.579773</td>\n",
       "      <td>124.897186</td>\n",
       "      <td>124.318657</td>\n",
       "      <td>134.522064</td>\n",
       "      <td>138.791565</td>\n",
       "      <td>...</td>\n",
       "      <td>12.657701</td>\n",
       "      <td>14.509855</td>\n",
       "      <td>18.643116</td>\n",
       "      <td>2.905979</td>\n",
       "      <td>2.252764</td>\n",
       "      <td>2.997747</td>\n",
       "      <td>3.173423</td>\n",
       "      <td>2.699984</td>\n",
       "      <td>2.714874</td>\n",
       "      <td>2.329038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.108329</td>\n",
       "      <td>0.018797</td>\n",
       "      <td>116.932335</td>\n",
       "      <td>116.810623</td>\n",
       "      <td>104.958511</td>\n",
       "      <td>106.856224</td>\n",
       "      <td>107.122963</td>\n",
       "      <td>131.222122</td>\n",
       "      <td>353.585815</td>\n",
       "      <td>128.099060</td>\n",
       "      <td>...</td>\n",
       "      <td>13.057364</td>\n",
       "      <td>13.359251</td>\n",
       "      <td>16.425354</td>\n",
       "      <td>2.510432</td>\n",
       "      <td>2.361842</td>\n",
       "      <td>2.691745</td>\n",
       "      <td>1.427239</td>\n",
       "      <td>2.369561</td>\n",
       "      <td>1.818932</td>\n",
       "      <td>2.163963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.203055</td>\n",
       "      <td>0.022426</td>\n",
       "      <td>319.182281</td>\n",
       "      <td>131.998932</td>\n",
       "      <td>131.480270</td>\n",
       "      <td>121.196114</td>\n",
       "      <td>121.224365</td>\n",
       "      <td>121.071152</td>\n",
       "      <td>131.966660</td>\n",
       "      <td>794.266663</td>\n",
       "      <td>...</td>\n",
       "      <td>12.970959</td>\n",
       "      <td>21.755045</td>\n",
       "      <td>21.717041</td>\n",
       "      <td>1.537123</td>\n",
       "      <td>1.638237</td>\n",
       "      <td>3.026752</td>\n",
       "      <td>1.810459</td>\n",
       "      <td>2.805019</td>\n",
       "      <td>4.571950</td>\n",
       "      <td>4.293758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.119210</td>\n",
       "      <td>0.032156</td>\n",
       "      <td>256.728058</td>\n",
       "      <td>515.784363</td>\n",
       "      <td>224.581177</td>\n",
       "      <td>112.526237</td>\n",
       "      <td>131.550888</td>\n",
       "      <td>131.923523</td>\n",
       "      <td>129.934570</td>\n",
       "      <td>115.061554</td>\n",
       "      <td>...</td>\n",
       "      <td>14.145430</td>\n",
       "      <td>15.075860</td>\n",
       "      <td>19.178572</td>\n",
       "      <td>2.318594</td>\n",
       "      <td>2.508579</td>\n",
       "      <td>1.901502</td>\n",
       "      <td>3.409710</td>\n",
       "      <td>2.446294</td>\n",
       "      <td>1.661939</td>\n",
       "      <td>3.035185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.113839</td>\n",
       "      <td>0.019690</td>\n",
       "      <td>116.983658</td>\n",
       "      <td>108.427589</td>\n",
       "      <td>108.570358</td>\n",
       "      <td>136.068344</td>\n",
       "      <td>135.782394</td>\n",
       "      <td>111.091484</td>\n",
       "      <td>111.612175</td>\n",
       "      <td>104.272835</td>\n",
       "      <td>...</td>\n",
       "      <td>12.054803</td>\n",
       "      <td>14.731396</td>\n",
       "      <td>17.400953</td>\n",
       "      <td>3.947008</td>\n",
       "      <td>1.956441</td>\n",
       "      <td>2.477308</td>\n",
       "      <td>3.416498</td>\n",
       "      <td>1.927335</td>\n",
       "      <td>1.812950</td>\n",
       "      <td>1.570067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119995</th>\n",
       "      <td>0.073382</td>\n",
       "      <td>0.043350</td>\n",
       "      <td>858.709106</td>\n",
       "      <td>859.935059</td>\n",
       "      <td>863.328430</td>\n",
       "      <td>4302.474121</td>\n",
       "      <td>4084.642578</td>\n",
       "      <td>3813.006836</td>\n",
       "      <td>3866.472412</td>\n",
       "      <td>4184.843750</td>\n",
       "      <td>...</td>\n",
       "      <td>17.373228</td>\n",
       "      <td>16.825651</td>\n",
       "      <td>22.475708</td>\n",
       "      <td>2.356882</td>\n",
       "      <td>2.618949</td>\n",
       "      <td>2.250412</td>\n",
       "      <td>2.331108</td>\n",
       "      <td>4.017359</td>\n",
       "      <td>2.289333</td>\n",
       "      <td>2.304441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119996</th>\n",
       "      <td>0.026786</td>\n",
       "      <td>0.021679</td>\n",
       "      <td>3544.072021</td>\n",
       "      <td>3636.010010</td>\n",
       "      <td>3683.929199</td>\n",
       "      <td>3720.447510</td>\n",
       "      <td>3778.039062</td>\n",
       "      <td>3810.043457</td>\n",
       "      <td>3821.472656</td>\n",
       "      <td>3775.821533</td>\n",
       "      <td>...</td>\n",
       "      <td>13.843332</td>\n",
       "      <td>15.092970</td>\n",
       "      <td>19.419765</td>\n",
       "      <td>1.739386</td>\n",
       "      <td>1.899920</td>\n",
       "      <td>2.972288</td>\n",
       "      <td>3.275728</td>\n",
       "      <td>3.504961</td>\n",
       "      <td>1.926326</td>\n",
       "      <td>1.559724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119997</th>\n",
       "      <td>0.000837</td>\n",
       "      <td>0.003018</td>\n",
       "      <td>3488.506104</td>\n",
       "      <td>3421.704102</td>\n",
       "      <td>3381.033447</td>\n",
       "      <td>3309.861572</td>\n",
       "      <td>3363.148926</td>\n",
       "      <td>3329.871582</td>\n",
       "      <td>3270.464844</td>\n",
       "      <td>3205.298096</td>\n",
       "      <td>...</td>\n",
       "      <td>13.192764</td>\n",
       "      <td>14.612162</td>\n",
       "      <td>16.889723</td>\n",
       "      <td>2.074640</td>\n",
       "      <td>3.095009</td>\n",
       "      <td>2.575306</td>\n",
       "      <td>3.005124</td>\n",
       "      <td>2.567822</td>\n",
       "      <td>2.403719</td>\n",
       "      <td>0.977590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119998</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2856.960938</td>\n",
       "      <td>2819.917480</td>\n",
       "      <td>2707.269775</td>\n",
       "      <td>5311.467773</td>\n",
       "      <td>2821.321533</td>\n",
       "      <td>2906.507568</td>\n",
       "      <td>2896.592285</td>\n",
       "      <td>2886.045166</td>\n",
       "      <td>...</td>\n",
       "      <td>13.242117</td>\n",
       "      <td>16.405230</td>\n",
       "      <td>17.726557</td>\n",
       "      <td>3.940534</td>\n",
       "      <td>3.248955</td>\n",
       "      <td>4.130877</td>\n",
       "      <td>1.688196</td>\n",
       "      <td>3.651503</td>\n",
       "      <td>3.851557</td>\n",
       "      <td>1.590729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119999</th>\n",
       "      <td>0.009556</td>\n",
       "      <td>0.013782</td>\n",
       "      <td>1049.992798</td>\n",
       "      <td>3424.807861</td>\n",
       "      <td>4180.444336</td>\n",
       "      <td>4065.649170</td>\n",
       "      <td>4097.248047</td>\n",
       "      <td>3817.443848</td>\n",
       "      <td>3588.379883</td>\n",
       "      <td>3599.223389</td>\n",
       "      <td>...</td>\n",
       "      <td>11.585784</td>\n",
       "      <td>16.248142</td>\n",
       "      <td>17.693525</td>\n",
       "      <td>2.985596</td>\n",
       "      <td>2.078395</td>\n",
       "      <td>3.595087</td>\n",
       "      <td>4.647794</td>\n",
       "      <td>4.181589</td>\n",
       "      <td>2.203514</td>\n",
       "      <td>1.436555</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120000 rows × 548 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        zcr_mean   zcr_std        yin_0        yin_1        yin_2  \\\n",
       "0       0.104213  0.025389   144.178635   167.021698   115.430466   \n",
       "1       0.108329  0.018797   116.932335   116.810623   104.958511   \n",
       "2       0.203055  0.022426   319.182281   131.998932   131.480270   \n",
       "3       0.119210  0.032156   256.728058   515.784363   224.581177   \n",
       "4       0.113839  0.019690   116.983658   108.427589   108.570358   \n",
       "...          ...       ...          ...          ...          ...   \n",
       "119995  0.073382  0.043350   858.709106   859.935059   863.328430   \n",
       "119996  0.026786  0.021679  3544.072021  3636.010010  3683.929199   \n",
       "119997  0.000837  0.003018  3488.506104  3421.704102  3381.033447   \n",
       "119998  0.000000  0.000000  2856.960938  2819.917480  2707.269775   \n",
       "119999  0.009556  0.013782  1049.992798  3424.807861  4180.444336   \n",
       "\n",
       "              yin_3        yin_4        yin_5        yin_6        yin_7  ...  \\\n",
       "0        115.579773   124.897186   124.318657   134.522064   138.791565  ...   \n",
       "1        106.856224   107.122963   131.222122   353.585815   128.099060  ...   \n",
       "2        121.196114   121.224365   121.071152   131.966660   794.266663  ...   \n",
       "3        112.526237   131.550888   131.923523   129.934570   115.061554  ...   \n",
       "4        136.068344   135.782394   111.091484   111.612175   104.272835  ...   \n",
       "...             ...          ...          ...          ...          ...  ...   \n",
       "119995  4302.474121  4084.642578  3813.006836  3866.472412  4184.843750  ...   \n",
       "119996  3720.447510  3778.039062  3810.043457  3821.472656  3775.821533  ...   \n",
       "119997  3309.861572  3363.148926  3329.871582  3270.464844  3205.298096  ...   \n",
       "119998  5311.467773  2821.321533  2906.507568  2896.592285  2886.045166  ...   \n",
       "119999  4065.649170  4097.248047  3817.443848  3588.379883  3599.223389  ...   \n",
       "\n",
       "        cln_contrast_mean_4  cln_contrast_mean_5  cln_contrast_mean_6  \\\n",
       "0                 12.657701            14.509855            18.643116   \n",
       "1                 13.057364            13.359251            16.425354   \n",
       "2                 12.970959            21.755045            21.717041   \n",
       "3                 14.145430            15.075860            19.178572   \n",
       "4                 12.054803            14.731396            17.400953   \n",
       "...                     ...                  ...                  ...   \n",
       "119995            17.373228            16.825651            22.475708   \n",
       "119996            13.843332            15.092970            19.419765   \n",
       "119997            13.192764            14.612162            16.889723   \n",
       "119998            13.242117            16.405230            17.726557   \n",
       "119999            11.585784            16.248142            17.693525   \n",
       "\n",
       "        cln_contrast_std_0  cln_contrast_std_1  cln_contrast_std_2  \\\n",
       "0                 2.905979            2.252764            2.997747   \n",
       "1                 2.510432            2.361842            2.691745   \n",
       "2                 1.537123            1.638237            3.026752   \n",
       "3                 2.318594            2.508579            1.901502   \n",
       "4                 3.947008            1.956441            2.477308   \n",
       "...                    ...                 ...                 ...   \n",
       "119995            2.356882            2.618949            2.250412   \n",
       "119996            1.739386            1.899920            2.972288   \n",
       "119997            2.074640            3.095009            2.575306   \n",
       "119998            3.940534            3.248955            4.130877   \n",
       "119999            2.985596            2.078395            3.595087   \n",
       "\n",
       "        cln_contrast_std_3  cln_contrast_std_4  cln_contrast_std_5  \\\n",
       "0                 3.173423            2.699984            2.714874   \n",
       "1                 1.427239            2.369561            1.818932   \n",
       "2                 1.810459            2.805019            4.571950   \n",
       "3                 3.409710            2.446294            1.661939   \n",
       "4                 3.416498            1.927335            1.812950   \n",
       "...                    ...                 ...                 ...   \n",
       "119995            2.331108            4.017359            2.289333   \n",
       "119996            3.275728            3.504961            1.926326   \n",
       "119997            3.005124            2.567822            2.403719   \n",
       "119998            1.688196            3.651503            3.851557   \n",
       "119999            4.647794            4.181589            2.203514   \n",
       "\n",
       "        cln_contrast_std_6  \n",
       "0                 2.329038  \n",
       "1                 2.163963  \n",
       "2                 4.293758  \n",
       "3                 3.035185  \n",
       "4                 1.570067  \n",
       "...                    ...  \n",
       "119995            2.304441  \n",
       "119996            1.559724  \n",
       "119997            0.977590  \n",
       "119998            1.590729  \n",
       "119999            1.436555  \n",
       "\n",
       "[120000 rows x 548 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = pd.DataFrame(all_ffiles, columns = feature_names)\n",
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "320a2e1a",
   "metadata": {
    "id": "320a2e1a"
   },
   "source": [
    "<h3 style=\"color:rgb(0,120,170)\">2. Feature Selection</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "a59d0ca4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>zcr_mean</th>\n",
       "      <th>zcr_std</th>\n",
       "      <th>yin_0</th>\n",
       "      <th>yin_1</th>\n",
       "      <th>yin_2</th>\n",
       "      <th>yin_3</th>\n",
       "      <th>yin_4</th>\n",
       "      <th>yin_5</th>\n",
       "      <th>yin_6</th>\n",
       "      <th>yin_7</th>\n",
       "      <th>...</th>\n",
       "      <th>cln_contrast_mean_4</th>\n",
       "      <th>cln_contrast_mean_5</th>\n",
       "      <th>cln_contrast_mean_6</th>\n",
       "      <th>cln_contrast_std_0</th>\n",
       "      <th>cln_contrast_std_1</th>\n",
       "      <th>cln_contrast_std_2</th>\n",
       "      <th>cln_contrast_std_3</th>\n",
       "      <th>cln_contrast_std_4</th>\n",
       "      <th>cln_contrast_std_5</th>\n",
       "      <th>cln_contrast_std_6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.104213</td>\n",
       "      <td>0.025389</td>\n",
       "      <td>144.178635</td>\n",
       "      <td>167.021698</td>\n",
       "      <td>115.430466</td>\n",
       "      <td>115.579773</td>\n",
       "      <td>124.897186</td>\n",
       "      <td>124.318657</td>\n",
       "      <td>134.522064</td>\n",
       "      <td>138.791565</td>\n",
       "      <td>...</td>\n",
       "      <td>12.657701</td>\n",
       "      <td>14.509855</td>\n",
       "      <td>18.643116</td>\n",
       "      <td>2.905979</td>\n",
       "      <td>2.252764</td>\n",
       "      <td>2.997747</td>\n",
       "      <td>3.173423</td>\n",
       "      <td>2.699984</td>\n",
       "      <td>2.714874</td>\n",
       "      <td>2.329038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.108329</td>\n",
       "      <td>0.018797</td>\n",
       "      <td>116.932335</td>\n",
       "      <td>116.810623</td>\n",
       "      <td>104.958511</td>\n",
       "      <td>106.856224</td>\n",
       "      <td>107.122963</td>\n",
       "      <td>131.222122</td>\n",
       "      <td>353.585815</td>\n",
       "      <td>128.099060</td>\n",
       "      <td>...</td>\n",
       "      <td>13.057364</td>\n",
       "      <td>13.359251</td>\n",
       "      <td>16.425354</td>\n",
       "      <td>2.510432</td>\n",
       "      <td>2.361842</td>\n",
       "      <td>2.691745</td>\n",
       "      <td>1.427239</td>\n",
       "      <td>2.369561</td>\n",
       "      <td>1.818932</td>\n",
       "      <td>2.163963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.203055</td>\n",
       "      <td>0.022426</td>\n",
       "      <td>319.182281</td>\n",
       "      <td>131.998932</td>\n",
       "      <td>131.480270</td>\n",
       "      <td>121.196114</td>\n",
       "      <td>121.224365</td>\n",
       "      <td>121.071152</td>\n",
       "      <td>131.966660</td>\n",
       "      <td>794.266663</td>\n",
       "      <td>...</td>\n",
       "      <td>12.970959</td>\n",
       "      <td>21.755045</td>\n",
       "      <td>21.717041</td>\n",
       "      <td>1.537123</td>\n",
       "      <td>1.638237</td>\n",
       "      <td>3.026752</td>\n",
       "      <td>1.810459</td>\n",
       "      <td>2.805019</td>\n",
       "      <td>4.571950</td>\n",
       "      <td>4.293758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.119210</td>\n",
       "      <td>0.032156</td>\n",
       "      <td>256.728058</td>\n",
       "      <td>515.784363</td>\n",
       "      <td>224.581177</td>\n",
       "      <td>112.526237</td>\n",
       "      <td>131.550888</td>\n",
       "      <td>131.923523</td>\n",
       "      <td>129.934570</td>\n",
       "      <td>115.061554</td>\n",
       "      <td>...</td>\n",
       "      <td>14.145430</td>\n",
       "      <td>15.075860</td>\n",
       "      <td>19.178572</td>\n",
       "      <td>2.318594</td>\n",
       "      <td>2.508579</td>\n",
       "      <td>1.901502</td>\n",
       "      <td>3.409710</td>\n",
       "      <td>2.446294</td>\n",
       "      <td>1.661939</td>\n",
       "      <td>3.035185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.113839</td>\n",
       "      <td>0.019690</td>\n",
       "      <td>116.983658</td>\n",
       "      <td>108.427589</td>\n",
       "      <td>108.570358</td>\n",
       "      <td>136.068344</td>\n",
       "      <td>135.782394</td>\n",
       "      <td>111.091484</td>\n",
       "      <td>111.612175</td>\n",
       "      <td>104.272835</td>\n",
       "      <td>...</td>\n",
       "      <td>12.054803</td>\n",
       "      <td>14.731396</td>\n",
       "      <td>17.400953</td>\n",
       "      <td>3.947008</td>\n",
       "      <td>1.956441</td>\n",
       "      <td>2.477308</td>\n",
       "      <td>3.416498</td>\n",
       "      <td>1.927335</td>\n",
       "      <td>1.812950</td>\n",
       "      <td>1.570067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119995</th>\n",
       "      <td>0.073382</td>\n",
       "      <td>0.043350</td>\n",
       "      <td>858.709106</td>\n",
       "      <td>859.935059</td>\n",
       "      <td>863.328430</td>\n",
       "      <td>4302.474121</td>\n",
       "      <td>4084.642578</td>\n",
       "      <td>3813.006836</td>\n",
       "      <td>3866.472412</td>\n",
       "      <td>4184.843750</td>\n",
       "      <td>...</td>\n",
       "      <td>17.373228</td>\n",
       "      <td>16.825651</td>\n",
       "      <td>22.475708</td>\n",
       "      <td>2.356882</td>\n",
       "      <td>2.618949</td>\n",
       "      <td>2.250412</td>\n",
       "      <td>2.331108</td>\n",
       "      <td>4.017359</td>\n",
       "      <td>2.289333</td>\n",
       "      <td>2.304441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119996</th>\n",
       "      <td>0.026786</td>\n",
       "      <td>0.021679</td>\n",
       "      <td>3544.072021</td>\n",
       "      <td>3636.010010</td>\n",
       "      <td>3683.929199</td>\n",
       "      <td>3720.447510</td>\n",
       "      <td>3778.039062</td>\n",
       "      <td>3810.043457</td>\n",
       "      <td>3821.472656</td>\n",
       "      <td>3775.821533</td>\n",
       "      <td>...</td>\n",
       "      <td>13.843332</td>\n",
       "      <td>15.092970</td>\n",
       "      <td>19.419765</td>\n",
       "      <td>1.739386</td>\n",
       "      <td>1.899920</td>\n",
       "      <td>2.972288</td>\n",
       "      <td>3.275728</td>\n",
       "      <td>3.504961</td>\n",
       "      <td>1.926326</td>\n",
       "      <td>1.559724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119997</th>\n",
       "      <td>0.000837</td>\n",
       "      <td>0.003018</td>\n",
       "      <td>3488.506104</td>\n",
       "      <td>3421.704102</td>\n",
       "      <td>3381.033447</td>\n",
       "      <td>3309.861572</td>\n",
       "      <td>3363.148926</td>\n",
       "      <td>3329.871582</td>\n",
       "      <td>3270.464844</td>\n",
       "      <td>3205.298096</td>\n",
       "      <td>...</td>\n",
       "      <td>13.192764</td>\n",
       "      <td>14.612162</td>\n",
       "      <td>16.889723</td>\n",
       "      <td>2.074640</td>\n",
       "      <td>3.095009</td>\n",
       "      <td>2.575306</td>\n",
       "      <td>3.005124</td>\n",
       "      <td>2.567822</td>\n",
       "      <td>2.403719</td>\n",
       "      <td>0.977590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119998</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2856.960938</td>\n",
       "      <td>2819.917480</td>\n",
       "      <td>2707.269775</td>\n",
       "      <td>5311.467773</td>\n",
       "      <td>2821.321533</td>\n",
       "      <td>2906.507568</td>\n",
       "      <td>2896.592285</td>\n",
       "      <td>2886.045166</td>\n",
       "      <td>...</td>\n",
       "      <td>13.242117</td>\n",
       "      <td>16.405230</td>\n",
       "      <td>17.726557</td>\n",
       "      <td>3.940534</td>\n",
       "      <td>3.248955</td>\n",
       "      <td>4.130877</td>\n",
       "      <td>1.688196</td>\n",
       "      <td>3.651503</td>\n",
       "      <td>3.851557</td>\n",
       "      <td>1.590729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119999</th>\n",
       "      <td>0.009556</td>\n",
       "      <td>0.013782</td>\n",
       "      <td>1049.992798</td>\n",
       "      <td>3424.807861</td>\n",
       "      <td>4180.444336</td>\n",
       "      <td>4065.649170</td>\n",
       "      <td>4097.248047</td>\n",
       "      <td>3817.443848</td>\n",
       "      <td>3588.379883</td>\n",
       "      <td>3599.223389</td>\n",
       "      <td>...</td>\n",
       "      <td>11.585784</td>\n",
       "      <td>16.248142</td>\n",
       "      <td>17.693525</td>\n",
       "      <td>2.985596</td>\n",
       "      <td>2.078395</td>\n",
       "      <td>3.595087</td>\n",
       "      <td>4.647794</td>\n",
       "      <td>4.181589</td>\n",
       "      <td>2.203514</td>\n",
       "      <td>1.436555</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120000 rows × 548 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        zcr_mean   zcr_std        yin_0        yin_1        yin_2  \\\n",
       "0       0.104213  0.025389   144.178635   167.021698   115.430466   \n",
       "1       0.108329  0.018797   116.932335   116.810623   104.958511   \n",
       "2       0.203055  0.022426   319.182281   131.998932   131.480270   \n",
       "3       0.119210  0.032156   256.728058   515.784363   224.581177   \n",
       "4       0.113839  0.019690   116.983658   108.427589   108.570358   \n",
       "...          ...       ...          ...          ...          ...   \n",
       "119995  0.073382  0.043350   858.709106   859.935059   863.328430   \n",
       "119996  0.026786  0.021679  3544.072021  3636.010010  3683.929199   \n",
       "119997  0.000837  0.003018  3488.506104  3421.704102  3381.033447   \n",
       "119998  0.000000  0.000000  2856.960938  2819.917480  2707.269775   \n",
       "119999  0.009556  0.013782  1049.992798  3424.807861  4180.444336   \n",
       "\n",
       "              yin_3        yin_4        yin_5        yin_6        yin_7  ...  \\\n",
       "0        115.579773   124.897186   124.318657   134.522064   138.791565  ...   \n",
       "1        106.856224   107.122963   131.222122   353.585815   128.099060  ...   \n",
       "2        121.196114   121.224365   121.071152   131.966660   794.266663  ...   \n",
       "3        112.526237   131.550888   131.923523   129.934570   115.061554  ...   \n",
       "4        136.068344   135.782394   111.091484   111.612175   104.272835  ...   \n",
       "...             ...          ...          ...          ...          ...  ...   \n",
       "119995  4302.474121  4084.642578  3813.006836  3866.472412  4184.843750  ...   \n",
       "119996  3720.447510  3778.039062  3810.043457  3821.472656  3775.821533  ...   \n",
       "119997  3309.861572  3363.148926  3329.871582  3270.464844  3205.298096  ...   \n",
       "119998  5311.467773  2821.321533  2906.507568  2896.592285  2886.045166  ...   \n",
       "119999  4065.649170  4097.248047  3817.443848  3588.379883  3599.223389  ...   \n",
       "\n",
       "        cln_contrast_mean_4  cln_contrast_mean_5  cln_contrast_mean_6  \\\n",
       "0                 12.657701            14.509855            18.643116   \n",
       "1                 13.057364            13.359251            16.425354   \n",
       "2                 12.970959            21.755045            21.717041   \n",
       "3                 14.145430            15.075860            19.178572   \n",
       "4                 12.054803            14.731396            17.400953   \n",
       "...                     ...                  ...                  ...   \n",
       "119995            17.373228            16.825651            22.475708   \n",
       "119996            13.843332            15.092970            19.419765   \n",
       "119997            13.192764            14.612162            16.889723   \n",
       "119998            13.242117            16.405230            17.726557   \n",
       "119999            11.585784            16.248142            17.693525   \n",
       "\n",
       "        cln_contrast_std_0  cln_contrast_std_1  cln_contrast_std_2  \\\n",
       "0                 2.905979            2.252764            2.997747   \n",
       "1                 2.510432            2.361842            2.691745   \n",
       "2                 1.537123            1.638237            3.026752   \n",
       "3                 2.318594            2.508579            1.901502   \n",
       "4                 3.947008            1.956441            2.477308   \n",
       "...                    ...                 ...                 ...   \n",
       "119995            2.356882            2.618949            2.250412   \n",
       "119996            1.739386            1.899920            2.972288   \n",
       "119997            2.074640            3.095009            2.575306   \n",
       "119998            3.940534            3.248955            4.130877   \n",
       "119999            2.985596            2.078395            3.595087   \n",
       "\n",
       "        cln_contrast_std_3  cln_contrast_std_4  cln_contrast_std_5  \\\n",
       "0                 3.173423            2.699984            2.714874   \n",
       "1                 1.427239            2.369561            1.818932   \n",
       "2                 1.810459            2.805019            4.571950   \n",
       "3                 3.409710            2.446294            1.661939   \n",
       "4                 3.416498            1.927335            1.812950   \n",
       "...                    ...                 ...                 ...   \n",
       "119995            2.331108            4.017359            2.289333   \n",
       "119996            3.275728            3.504961            1.926326   \n",
       "119997            3.005124            2.567822            2.403719   \n",
       "119998            1.688196            3.651503            3.851557   \n",
       "119999            4.647794            4.181589            2.203514   \n",
       "\n",
       "        cln_contrast_std_6  \n",
       "0                 2.329038  \n",
       "1                 2.163963  \n",
       "2                 4.293758  \n",
       "3                 3.035185  \n",
       "4                 1.570067  \n",
       "...                    ...  \n",
       "119995            2.304441  \n",
       "119996            1.559724  \n",
       "119997            0.977590  \n",
       "119998            1.590729  \n",
       "119999            1.436555  \n",
       "\n",
       "[120000 rows x 548 columns]"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "DRpO0R3sr-tQ",
   "metadata": {
    "id": "DRpO0R3sr-tQ"
   },
   "source": [
    "<h3 style=\"color:rgb(0,120,170)\">2.2. Feature Selection</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "93403811",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA()\n",
    "pca.fit(selected_features)\n",
    "\n",
    "explained_variance_ratio = pca.explained_variance_ratio_\n",
    "cumulative_explained_variance = np.cumsum(explained_variance_ratio)\n",
    "\n",
    "# Create the scree plot\n",
    "component_numbers = np.arange(1, len(explained_variances) + 1)\n",
    "plt.bar(component_numbers, explained_variances)\n",
    "plt.xlabel('Number of Components')\n",
    "plt.ylabel('Explained Variance Ratio')\n",
    "plt.title('Scree Plot')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "91c913ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>zcr_mean</th>\n",
       "      <th>zcr_std</th>\n",
       "      <th>yin_0</th>\n",
       "      <th>raw_melspect_mean_0</th>\n",
       "      <th>raw_melspect_std_4</th>\n",
       "      <th>raw_melspect_std_8</th>\n",
       "      <th>raw_melspect_std_13</th>\n",
       "      <th>raw_melspect_std_52</th>\n",
       "      <th>raw_mfcc_mean_0</th>\n",
       "      <th>raw_mfcc_mean_2</th>\n",
       "      <th>...</th>\n",
       "      <th>cln_mfcc_mean_0</th>\n",
       "      <th>cln_mfcc_mean_1</th>\n",
       "      <th>cln_mfcc_mean_2</th>\n",
       "      <th>cln_mfcc_mean_4</th>\n",
       "      <th>cln_mfcc_mean_5</th>\n",
       "      <th>cln_mfcc_mean_15</th>\n",
       "      <th>cln_mfcc_mean_17</th>\n",
       "      <th>cln_centroid_mean</th>\n",
       "      <th>cln_contrast_mean_0</th>\n",
       "      <th>cln_contrast_mean_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>zcr_mean</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.457498</td>\n",
       "      <td>0.039588</td>\n",
       "      <td>-0.406481</td>\n",
       "      <td>-0.069462</td>\n",
       "      <td>-0.132583</td>\n",
       "      <td>-0.009747</td>\n",
       "      <td>0.251856</td>\n",
       "      <td>0.049904</td>\n",
       "      <td>-0.337260</td>\n",
       "      <td>...</td>\n",
       "      <td>0.032492</td>\n",
       "      <td>-0.334995</td>\n",
       "      <td>-0.115234</td>\n",
       "      <td>-0.101758</td>\n",
       "      <td>0.152715</td>\n",
       "      <td>-0.059877</td>\n",
       "      <td>-0.078351</td>\n",
       "      <td>0.155353</td>\n",
       "      <td>0.144840</td>\n",
       "      <td>-0.031695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zcr_std</th>\n",
       "      <td>0.457498</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.102195</td>\n",
       "      <td>-0.104737</td>\n",
       "      <td>0.110815</td>\n",
       "      <td>0.139176</td>\n",
       "      <td>0.103763</td>\n",
       "      <td>0.449087</td>\n",
       "      <td>0.112943</td>\n",
       "      <td>-0.125048</td>\n",
       "      <td>...</td>\n",
       "      <td>0.071929</td>\n",
       "      <td>-0.262443</td>\n",
       "      <td>-0.010013</td>\n",
       "      <td>-0.125744</td>\n",
       "      <td>0.128377</td>\n",
       "      <td>-0.028595</td>\n",
       "      <td>-0.054313</td>\n",
       "      <td>0.089627</td>\n",
       "      <td>0.045560</td>\n",
       "      <td>0.002460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yin_0</th>\n",
       "      <td>0.039588</td>\n",
       "      <td>0.102195</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.026276</td>\n",
       "      <td>-0.030007</td>\n",
       "      <td>-0.022899</td>\n",
       "      <td>0.017780</td>\n",
       "      <td>0.101970</td>\n",
       "      <td>-0.065101</td>\n",
       "      <td>0.064637</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.095906</td>\n",
       "      <td>-0.142782</td>\n",
       "      <td>0.004591</td>\n",
       "      <td>-0.038984</td>\n",
       "      <td>0.094148</td>\n",
       "      <td>-0.026306</td>\n",
       "      <td>-0.033548</td>\n",
       "      <td>0.085164</td>\n",
       "      <td>-0.032167</td>\n",
       "      <td>0.047111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>raw_melspect_mean_0</th>\n",
       "      <td>-0.406481</td>\n",
       "      <td>-0.104737</td>\n",
       "      <td>0.026276</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.031475</td>\n",
       "      <td>0.026401</td>\n",
       "      <td>-0.061423</td>\n",
       "      <td>-0.075751</td>\n",
       "      <td>0.512624</td>\n",
       "      <td>0.424680</td>\n",
       "      <td>...</td>\n",
       "      <td>0.088795</td>\n",
       "      <td>0.074874</td>\n",
       "      <td>0.060768</td>\n",
       "      <td>0.043379</td>\n",
       "      <td>0.018687</td>\n",
       "      <td>0.039689</td>\n",
       "      <td>0.021386</td>\n",
       "      <td>0.009977</td>\n",
       "      <td>-0.036902</td>\n",
       "      <td>-0.030102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>raw_melspect_std_4</th>\n",
       "      <td>-0.069462</td>\n",
       "      <td>0.110815</td>\n",
       "      <td>-0.030007</td>\n",
       "      <td>0.031475</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.356758</td>\n",
       "      <td>0.302749</td>\n",
       "      <td>0.104577</td>\n",
       "      <td>-0.004862</td>\n",
       "      <td>0.097754</td>\n",
       "      <td>...</td>\n",
       "      <td>0.038399</td>\n",
       "      <td>0.143645</td>\n",
       "      <td>0.089852</td>\n",
       "      <td>0.036891</td>\n",
       "      <td>-0.010522</td>\n",
       "      <td>-0.030213</td>\n",
       "      <td>0.008594</td>\n",
       "      <td>-0.160002</td>\n",
       "      <td>0.039536</td>\n",
       "      <td>0.020924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cln_mfcc_mean_15</th>\n",
       "      <td>-0.059877</td>\n",
       "      <td>-0.028595</td>\n",
       "      <td>-0.026306</td>\n",
       "      <td>0.039689</td>\n",
       "      <td>-0.030213</td>\n",
       "      <td>0.138460</td>\n",
       "      <td>-0.052524</td>\n",
       "      <td>-0.057182</td>\n",
       "      <td>0.044172</td>\n",
       "      <td>0.016542</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006900</td>\n",
       "      <td>0.067102</td>\n",
       "      <td>0.071580</td>\n",
       "      <td>-0.014395</td>\n",
       "      <td>-0.081079</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.199448</td>\n",
       "      <td>-0.049818</td>\n",
       "      <td>0.016025</td>\n",
       "      <td>-0.005653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cln_mfcc_mean_17</th>\n",
       "      <td>-0.078351</td>\n",
       "      <td>-0.054313</td>\n",
       "      <td>-0.033548</td>\n",
       "      <td>0.021386</td>\n",
       "      <td>0.008594</td>\n",
       "      <td>0.020203</td>\n",
       "      <td>-0.013336</td>\n",
       "      <td>-0.083266</td>\n",
       "      <td>0.011198</td>\n",
       "      <td>0.024848</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011750</td>\n",
       "      <td>0.094574</td>\n",
       "      <td>0.043199</td>\n",
       "      <td>-0.008647</td>\n",
       "      <td>-0.052780</td>\n",
       "      <td>0.199448</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.098434</td>\n",
       "      <td>0.021264</td>\n",
       "      <td>-0.006287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cln_centroid_mean</th>\n",
       "      <td>0.155353</td>\n",
       "      <td>0.089627</td>\n",
       "      <td>0.085164</td>\n",
       "      <td>0.009977</td>\n",
       "      <td>-0.160002</td>\n",
       "      <td>-0.275864</td>\n",
       "      <td>-0.243456</td>\n",
       "      <td>0.040240</td>\n",
       "      <td>-0.110770</td>\n",
       "      <td>0.127855</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.341247</td>\n",
       "      <td>-0.490729</td>\n",
       "      <td>0.390870</td>\n",
       "      <td>0.180866</td>\n",
       "      <td>0.321316</td>\n",
       "      <td>-0.049818</td>\n",
       "      <td>-0.098434</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.038100</td>\n",
       "      <td>-0.080991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cln_contrast_mean_0</th>\n",
       "      <td>0.144840</td>\n",
       "      <td>0.045560</td>\n",
       "      <td>-0.032167</td>\n",
       "      <td>-0.036902</td>\n",
       "      <td>0.039536</td>\n",
       "      <td>-0.020225</td>\n",
       "      <td>0.004209</td>\n",
       "      <td>-0.009719</td>\n",
       "      <td>-0.021030</td>\n",
       "      <td>-0.013555</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.085656</td>\n",
       "      <td>-0.004776</td>\n",
       "      <td>0.009972</td>\n",
       "      <td>0.001878</td>\n",
       "      <td>0.005456</td>\n",
       "      <td>0.016025</td>\n",
       "      <td>0.021264</td>\n",
       "      <td>-0.038100</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.151593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cln_contrast_mean_1</th>\n",
       "      <td>-0.031695</td>\n",
       "      <td>0.002460</td>\n",
       "      <td>0.047111</td>\n",
       "      <td>-0.030102</td>\n",
       "      <td>0.020924</td>\n",
       "      <td>0.024451</td>\n",
       "      <td>0.025505</td>\n",
       "      <td>0.013879</td>\n",
       "      <td>-0.030026</td>\n",
       "      <td>-0.013954</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.102182</td>\n",
       "      <td>0.014185</td>\n",
       "      <td>0.005069</td>\n",
       "      <td>0.003002</td>\n",
       "      <td>0.001563</td>\n",
       "      <td>-0.005653</td>\n",
       "      <td>-0.006287</td>\n",
       "      <td>-0.080991</td>\n",
       "      <td>0.151593</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>66 rows × 66 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     zcr_mean   zcr_std     yin_0  raw_melspect_mean_0  \\\n",
       "zcr_mean             1.000000  0.457498  0.039588            -0.406481   \n",
       "zcr_std              0.457498  1.000000  0.102195            -0.104737   \n",
       "yin_0                0.039588  0.102195  1.000000             0.026276   \n",
       "raw_melspect_mean_0 -0.406481 -0.104737  0.026276             1.000000   \n",
       "raw_melspect_std_4  -0.069462  0.110815 -0.030007             0.031475   \n",
       "...                       ...       ...       ...                  ...   \n",
       "cln_mfcc_mean_15    -0.059877 -0.028595 -0.026306             0.039689   \n",
       "cln_mfcc_mean_17    -0.078351 -0.054313 -0.033548             0.021386   \n",
       "cln_centroid_mean    0.155353  0.089627  0.085164             0.009977   \n",
       "cln_contrast_mean_0  0.144840  0.045560 -0.032167            -0.036902   \n",
       "cln_contrast_mean_1 -0.031695  0.002460  0.047111            -0.030102   \n",
       "\n",
       "                     raw_melspect_std_4  raw_melspect_std_8  \\\n",
       "zcr_mean                      -0.069462           -0.132583   \n",
       "zcr_std                        0.110815            0.139176   \n",
       "yin_0                         -0.030007           -0.022899   \n",
       "raw_melspect_mean_0            0.031475            0.026401   \n",
       "raw_melspect_std_4             1.000000            0.356758   \n",
       "...                                 ...                 ...   \n",
       "cln_mfcc_mean_15              -0.030213            0.138460   \n",
       "cln_mfcc_mean_17               0.008594            0.020203   \n",
       "cln_centroid_mean             -0.160002           -0.275864   \n",
       "cln_contrast_mean_0            0.039536           -0.020225   \n",
       "cln_contrast_mean_1            0.020924            0.024451   \n",
       "\n",
       "                     raw_melspect_std_13  raw_melspect_std_52  \\\n",
       "zcr_mean                       -0.009747             0.251856   \n",
       "zcr_std                         0.103763             0.449087   \n",
       "yin_0                           0.017780             0.101970   \n",
       "raw_melspect_mean_0            -0.061423            -0.075751   \n",
       "raw_melspect_std_4              0.302749             0.104577   \n",
       "...                                  ...                  ...   \n",
       "cln_mfcc_mean_15               -0.052524            -0.057182   \n",
       "cln_mfcc_mean_17               -0.013336            -0.083266   \n",
       "cln_centroid_mean              -0.243456             0.040240   \n",
       "cln_contrast_mean_0             0.004209            -0.009719   \n",
       "cln_contrast_mean_1             0.025505             0.013879   \n",
       "\n",
       "                     raw_mfcc_mean_0  raw_mfcc_mean_2  ...  cln_mfcc_mean_0  \\\n",
       "zcr_mean                    0.049904        -0.337260  ...         0.032492   \n",
       "zcr_std                     0.112943        -0.125048  ...         0.071929   \n",
       "yin_0                      -0.065101         0.064637  ...        -0.095906   \n",
       "raw_melspect_mean_0         0.512624         0.424680  ...         0.088795   \n",
       "raw_melspect_std_4         -0.004862         0.097754  ...         0.038399   \n",
       "...                              ...              ...  ...              ...   \n",
       "cln_mfcc_mean_15            0.044172         0.016542  ...         0.006900   \n",
       "cln_mfcc_mean_17            0.011198         0.024848  ...         0.011750   \n",
       "cln_centroid_mean          -0.110770         0.127855  ...        -0.341247   \n",
       "cln_contrast_mean_0        -0.021030        -0.013555  ...        -0.085656   \n",
       "cln_contrast_mean_1        -0.030026        -0.013954  ...        -0.102182   \n",
       "\n",
       "                     cln_mfcc_mean_1  cln_mfcc_mean_2  cln_mfcc_mean_4  \\\n",
       "zcr_mean                   -0.334995        -0.115234        -0.101758   \n",
       "zcr_std                    -0.262443        -0.010013        -0.125744   \n",
       "yin_0                      -0.142782         0.004591        -0.038984   \n",
       "raw_melspect_mean_0         0.074874         0.060768         0.043379   \n",
       "raw_melspect_std_4          0.143645         0.089852         0.036891   \n",
       "...                              ...              ...              ...   \n",
       "cln_mfcc_mean_15            0.067102         0.071580        -0.014395   \n",
       "cln_mfcc_mean_17            0.094574         0.043199        -0.008647   \n",
       "cln_centroid_mean          -0.490729         0.390870         0.180866   \n",
       "cln_contrast_mean_0        -0.004776         0.009972         0.001878   \n",
       "cln_contrast_mean_1         0.014185         0.005069         0.003002   \n",
       "\n",
       "                     cln_mfcc_mean_5  cln_mfcc_mean_15  cln_mfcc_mean_17  \\\n",
       "zcr_mean                    0.152715         -0.059877         -0.078351   \n",
       "zcr_std                     0.128377         -0.028595         -0.054313   \n",
       "yin_0                       0.094148         -0.026306         -0.033548   \n",
       "raw_melspect_mean_0         0.018687          0.039689          0.021386   \n",
       "raw_melspect_std_4         -0.010522         -0.030213          0.008594   \n",
       "...                              ...               ...               ...   \n",
       "cln_mfcc_mean_15           -0.081079          1.000000          0.199448   \n",
       "cln_mfcc_mean_17           -0.052780          0.199448          1.000000   \n",
       "cln_centroid_mean           0.321316         -0.049818         -0.098434   \n",
       "cln_contrast_mean_0         0.005456          0.016025          0.021264   \n",
       "cln_contrast_mean_1         0.001563         -0.005653         -0.006287   \n",
       "\n",
       "                     cln_centroid_mean  cln_contrast_mean_0  \\\n",
       "zcr_mean                      0.155353             0.144840   \n",
       "zcr_std                       0.089627             0.045560   \n",
       "yin_0                         0.085164            -0.032167   \n",
       "raw_melspect_mean_0           0.009977            -0.036902   \n",
       "raw_melspect_std_4           -0.160002             0.039536   \n",
       "...                                ...                  ...   \n",
       "cln_mfcc_mean_15             -0.049818             0.016025   \n",
       "cln_mfcc_mean_17             -0.098434             0.021264   \n",
       "cln_centroid_mean             1.000000            -0.038100   \n",
       "cln_contrast_mean_0          -0.038100             1.000000   \n",
       "cln_contrast_mean_1          -0.080991             0.151593   \n",
       "\n",
       "                     cln_contrast_mean_1  \n",
       "zcr_mean                       -0.031695  \n",
       "zcr_std                         0.002460  \n",
       "yin_0                           0.047111  \n",
       "raw_melspect_mean_0            -0.030102  \n",
       "raw_melspect_std_4              0.020924  \n",
       "...                                  ...  \n",
       "cln_mfcc_mean_15               -0.005653  \n",
       "cln_mfcc_mean_17               -0.006287  \n",
       "cln_centroid_mean              -0.080991  \n",
       "cln_contrast_mean_0             0.151593  \n",
       "cln_contrast_mean_1             1.000000  \n",
       "\n",
       "[66 rows x 66 columns]"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sf2 = sf1.copy()\n",
    "feature_corr = sf2.corr().abs()\n",
    "\n",
    "upper_tri = feature_corr.where(np.triu(np.ones(feature_corr.shape),k=1).astype(bool))\n",
    "to_drop = [column for column in upper_tri.columns if any(upper_tri[column] > 0.80)]\n",
    "sf2.drop(to_drop, axis=1, inplace=True)\n",
    "\n",
    "sf2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "AFIxT26osJTv",
   "metadata": {
    "id": "AFIxT26osJTv"
   },
   "source": [
    "<h3 style=\"color:rgb(0,120,170)\">Eliminating High Inter-Features Correlation</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "SGyTWCsEU3w3",
   "metadata": {
    "id": "SGyTWCsEU3w3"
   },
   "outputs": [],
   "source": [
    "# Copy of features\n",
    "selected_features = features.copy()\n",
    "# Compute correlation matrix of features\n",
    "feature_corr = features.corr().abs()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "47_2JGTo3mOo",
   "metadata": {
    "id": "47_2JGTo3mOo"
   },
   "outputs": [],
   "source": [
    "# Taking the upper 65%\n",
    "upper_tri = feature_corr.where(np.triu(np.ones(feature_corr.shape),k=1).astype(bool))\n",
    "to_drop = [column for column in upper_tri.columns if any(upper_tri[column] > 0.65)]\n",
    "selected_features.drop(to_drop, axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "2f186408",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>zcr_mean</th>\n",
       "      <th>zcr_std</th>\n",
       "      <th>yin_0</th>\n",
       "      <th>raw_melspect_mean_0</th>\n",
       "      <th>raw_melspect_std_0</th>\n",
       "      <th>raw_mfcc_mean_1</th>\n",
       "      <th>raw_mfcc_mean_2</th>\n",
       "      <th>raw_mfcc_mean_3</th>\n",
       "      <th>raw_mfcc_mean_4</th>\n",
       "      <th>raw_mfcc_mean_5</th>\n",
       "      <th>...</th>\n",
       "      <th>cln_mfcc_mean_4</th>\n",
       "      <th>cln_mfcc_mean_5</th>\n",
       "      <th>cln_flatness_mean</th>\n",
       "      <th>cln_flatness_std</th>\n",
       "      <th>cln_centroid_mean</th>\n",
       "      <th>cln_flux_mean</th>\n",
       "      <th>cln_bandwidth_mean</th>\n",
       "      <th>cln_contrast_mean_0</th>\n",
       "      <th>cln_contrast_mean_1</th>\n",
       "      <th>cln_contrast_mean_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.104213</td>\n",
       "      <td>0.025389</td>\n",
       "      <td>144.178635</td>\n",
       "      <td>5.260280</td>\n",
       "      <td>0.678598</td>\n",
       "      <td>11.722803</td>\n",
       "      <td>-2.886116</td>\n",
       "      <td>1.625302</td>\n",
       "      <td>-0.766484</td>\n",
       "      <td>0.358663</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.130756</td>\n",
       "      <td>0.165595</td>\n",
       "      <td>0.235257</td>\n",
       "      <td>0.102272</td>\n",
       "      <td>6887.078613</td>\n",
       "      <td>6.298171</td>\n",
       "      <td>2884.992676</td>\n",
       "      <td>5.941001</td>\n",
       "      <td>5.571944</td>\n",
       "      <td>8.220659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.108329</td>\n",
       "      <td>0.018797</td>\n",
       "      <td>116.932335</td>\n",
       "      <td>6.485734</td>\n",
       "      <td>0.315136</td>\n",
       "      <td>13.808211</td>\n",
       "      <td>-5.056562</td>\n",
       "      <td>2.318141</td>\n",
       "      <td>-0.455920</td>\n",
       "      <td>0.028335</td>\n",
       "      <td>...</td>\n",
       "      <td>0.156415</td>\n",
       "      <td>-0.046879</td>\n",
       "      <td>0.403903</td>\n",
       "      <td>0.094919</td>\n",
       "      <td>5813.555176</td>\n",
       "      <td>9.268286</td>\n",
       "      <td>3186.814941</td>\n",
       "      <td>5.584007</td>\n",
       "      <td>6.089088</td>\n",
       "      <td>7.443485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.203055</td>\n",
       "      <td>0.022426</td>\n",
       "      <td>319.182281</td>\n",
       "      <td>7.089341</td>\n",
       "      <td>0.363829</td>\n",
       "      <td>13.450143</td>\n",
       "      <td>-4.334423</td>\n",
       "      <td>3.202057</td>\n",
       "      <td>-1.927366</td>\n",
       "      <td>0.460847</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.254867</td>\n",
       "      <td>0.380876</td>\n",
       "      <td>0.088798</td>\n",
       "      <td>0.067826</td>\n",
       "      <td>5557.483887</td>\n",
       "      <td>57.868095</td>\n",
       "      <td>2620.215820</td>\n",
       "      <td>4.375466</td>\n",
       "      <td>5.434949</td>\n",
       "      <td>7.736153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.119210</td>\n",
       "      <td>0.032156</td>\n",
       "      <td>256.728058</td>\n",
       "      <td>7.198322</td>\n",
       "      <td>0.459935</td>\n",
       "      <td>13.438527</td>\n",
       "      <td>-5.172253</td>\n",
       "      <td>3.509893</td>\n",
       "      <td>-1.106580</td>\n",
       "      <td>1.211608</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.415970</td>\n",
       "      <td>1.130988</td>\n",
       "      <td>0.262824</td>\n",
       "      <td>0.132288</td>\n",
       "      <td>5596.516113</td>\n",
       "      <td>31.806095</td>\n",
       "      <td>2747.145020</td>\n",
       "      <td>6.926789</td>\n",
       "      <td>6.850839</td>\n",
       "      <td>8.108602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.113839</td>\n",
       "      <td>0.019690</td>\n",
       "      <td>116.983658</td>\n",
       "      <td>7.488858</td>\n",
       "      <td>0.297487</td>\n",
       "      <td>15.132287</td>\n",
       "      <td>-6.222596</td>\n",
       "      <td>2.101814</td>\n",
       "      <td>0.111821</td>\n",
       "      <td>0.178368</td>\n",
       "      <td>...</td>\n",
       "      <td>0.859586</td>\n",
       "      <td>0.031872</td>\n",
       "      <td>0.331669</td>\n",
       "      <td>0.045000</td>\n",
       "      <td>5342.882812</td>\n",
       "      <td>19.879534</td>\n",
       "      <td>3198.522461</td>\n",
       "      <td>6.698604</td>\n",
       "      <td>6.036443</td>\n",
       "      <td>7.433480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119995</th>\n",
       "      <td>0.073382</td>\n",
       "      <td>0.043350</td>\n",
       "      <td>858.709106</td>\n",
       "      <td>5.594575</td>\n",
       "      <td>0.236835</td>\n",
       "      <td>4.621610</td>\n",
       "      <td>-2.240215</td>\n",
       "      <td>2.218656</td>\n",
       "      <td>-4.246311</td>\n",
       "      <td>-2.819625</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.681545</td>\n",
       "      <td>-3.063332</td>\n",
       "      <td>0.068536</td>\n",
       "      <td>0.045667</td>\n",
       "      <td>4001.078125</td>\n",
       "      <td>182.219864</td>\n",
       "      <td>3285.902588</td>\n",
       "      <td>3.968847</td>\n",
       "      <td>6.502321</td>\n",
       "      <td>8.068604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119996</th>\n",
       "      <td>0.026786</td>\n",
       "      <td>0.021679</td>\n",
       "      <td>3544.072021</td>\n",
       "      <td>5.809918</td>\n",
       "      <td>0.225777</td>\n",
       "      <td>3.714819</td>\n",
       "      <td>-3.111917</td>\n",
       "      <td>3.491264</td>\n",
       "      <td>-2.134536</td>\n",
       "      <td>-2.273956</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.555302</td>\n",
       "      <td>-2.513235</td>\n",
       "      <td>0.180928</td>\n",
       "      <td>0.058953</td>\n",
       "      <td>4488.748535</td>\n",
       "      <td>62.407768</td>\n",
       "      <td>3333.172852</td>\n",
       "      <td>4.305187</td>\n",
       "      <td>4.845993</td>\n",
       "      <td>8.952189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119997</th>\n",
       "      <td>0.000837</td>\n",
       "      <td>0.003018</td>\n",
       "      <td>3488.506104</td>\n",
       "      <td>5.712483</td>\n",
       "      <td>0.378321</td>\n",
       "      <td>2.558474</td>\n",
       "      <td>-2.490510</td>\n",
       "      <td>5.043571</td>\n",
       "      <td>-1.124422</td>\n",
       "      <td>-1.422877</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.545844</td>\n",
       "      <td>-1.647332</td>\n",
       "      <td>0.328268</td>\n",
       "      <td>0.037066</td>\n",
       "      <td>4939.418457</td>\n",
       "      <td>21.312246</td>\n",
       "      <td>3299.661377</td>\n",
       "      <td>3.660138</td>\n",
       "      <td>6.617898</td>\n",
       "      <td>8.227812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119998</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2856.960938</td>\n",
       "      <td>5.624564</td>\n",
       "      <td>0.352010</td>\n",
       "      <td>1.487618</td>\n",
       "      <td>-2.024539</td>\n",
       "      <td>4.984841</td>\n",
       "      <td>-1.077376</td>\n",
       "      <td>-0.411108</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.506265</td>\n",
       "      <td>-0.645174</td>\n",
       "      <td>0.302483</td>\n",
       "      <td>0.040981</td>\n",
       "      <td>5235.270020</td>\n",
       "      <td>25.521641</td>\n",
       "      <td>3105.989258</td>\n",
       "      <td>4.346611</td>\n",
       "      <td>6.420346</td>\n",
       "      <td>8.649150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119999</th>\n",
       "      <td>0.009556</td>\n",
       "      <td>0.013782</td>\n",
       "      <td>1049.992798</td>\n",
       "      <td>6.037226</td>\n",
       "      <td>0.719046</td>\n",
       "      <td>1.214382</td>\n",
       "      <td>-1.621043</td>\n",
       "      <td>5.934211</td>\n",
       "      <td>-0.822477</td>\n",
       "      <td>-1.037465</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.233313</td>\n",
       "      <td>-1.268727</td>\n",
       "      <td>0.324750</td>\n",
       "      <td>0.082254</td>\n",
       "      <td>5359.769531</td>\n",
       "      <td>30.723736</td>\n",
       "      <td>3101.273926</td>\n",
       "      <td>5.006388</td>\n",
       "      <td>6.573549</td>\n",
       "      <td>7.939662</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120000 rows × 112 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        zcr_mean   zcr_std        yin_0  raw_melspect_mean_0  \\\n",
       "0       0.104213  0.025389   144.178635             5.260280   \n",
       "1       0.108329  0.018797   116.932335             6.485734   \n",
       "2       0.203055  0.022426   319.182281             7.089341   \n",
       "3       0.119210  0.032156   256.728058             7.198322   \n",
       "4       0.113839  0.019690   116.983658             7.488858   \n",
       "...          ...       ...          ...                  ...   \n",
       "119995  0.073382  0.043350   858.709106             5.594575   \n",
       "119996  0.026786  0.021679  3544.072021             5.809918   \n",
       "119997  0.000837  0.003018  3488.506104             5.712483   \n",
       "119998  0.000000  0.000000  2856.960938             5.624564   \n",
       "119999  0.009556  0.013782  1049.992798             6.037226   \n",
       "\n",
       "        raw_melspect_std_0  raw_mfcc_mean_1  raw_mfcc_mean_2  raw_mfcc_mean_3  \\\n",
       "0                 0.678598        11.722803        -2.886116         1.625302   \n",
       "1                 0.315136        13.808211        -5.056562         2.318141   \n",
       "2                 0.363829        13.450143        -4.334423         3.202057   \n",
       "3                 0.459935        13.438527        -5.172253         3.509893   \n",
       "4                 0.297487        15.132287        -6.222596         2.101814   \n",
       "...                    ...              ...              ...              ...   \n",
       "119995            0.236835         4.621610        -2.240215         2.218656   \n",
       "119996            0.225777         3.714819        -3.111917         3.491264   \n",
       "119997            0.378321         2.558474        -2.490510         5.043571   \n",
       "119998            0.352010         1.487618        -2.024539         4.984841   \n",
       "119999            0.719046         1.214382        -1.621043         5.934211   \n",
       "\n",
       "        raw_mfcc_mean_4  raw_mfcc_mean_5  ...  cln_mfcc_mean_4  \\\n",
       "0             -0.766484         0.358663  ...        -0.130756   \n",
       "1             -0.455920         0.028335  ...         0.156415   \n",
       "2             -1.927366         0.460847  ...        -1.254867   \n",
       "3             -1.106580         1.211608  ...        -0.415970   \n",
       "4              0.111821         0.178368  ...         0.859586   \n",
       "...                 ...              ...  ...              ...   \n",
       "119995        -4.246311        -2.819625  ...        -4.681545   \n",
       "119996        -2.134536        -2.273956  ...        -2.555302   \n",
       "119997        -1.124422        -1.422877  ...        -1.545844   \n",
       "119998        -1.077376        -0.411108  ...        -1.506265   \n",
       "119999        -0.822477        -1.037465  ...        -1.233313   \n",
       "\n",
       "        cln_mfcc_mean_5  cln_flatness_mean  cln_flatness_std  \\\n",
       "0              0.165595           0.235257          0.102272   \n",
       "1             -0.046879           0.403903          0.094919   \n",
       "2              0.380876           0.088798          0.067826   \n",
       "3              1.130988           0.262824          0.132288   \n",
       "4              0.031872           0.331669          0.045000   \n",
       "...                 ...                ...               ...   \n",
       "119995        -3.063332           0.068536          0.045667   \n",
       "119996        -2.513235           0.180928          0.058953   \n",
       "119997        -1.647332           0.328268          0.037066   \n",
       "119998        -0.645174           0.302483          0.040981   \n",
       "119999        -1.268727           0.324750          0.082254   \n",
       "\n",
       "        cln_centroid_mean  cln_flux_mean  cln_bandwidth_mean  \\\n",
       "0             6887.078613       6.298171         2884.992676   \n",
       "1             5813.555176       9.268286         3186.814941   \n",
       "2             5557.483887      57.868095         2620.215820   \n",
       "3             5596.516113      31.806095         2747.145020   \n",
       "4             5342.882812      19.879534         3198.522461   \n",
       "...                   ...            ...                 ...   \n",
       "119995        4001.078125     182.219864         3285.902588   \n",
       "119996        4488.748535      62.407768         3333.172852   \n",
       "119997        4939.418457      21.312246         3299.661377   \n",
       "119998        5235.270020      25.521641         3105.989258   \n",
       "119999        5359.769531      30.723736         3101.273926   \n",
       "\n",
       "        cln_contrast_mean_0  cln_contrast_mean_1  cln_contrast_mean_2  \n",
       "0                  5.941001             5.571944             8.220659  \n",
       "1                  5.584007             6.089088             7.443485  \n",
       "2                  4.375466             5.434949             7.736153  \n",
       "3                  6.926789             6.850839             8.108602  \n",
       "4                  6.698604             6.036443             7.433480  \n",
       "...                     ...                  ...                  ...  \n",
       "119995             3.968847             6.502321             8.068604  \n",
       "119996             4.305187             4.845993             8.952189  \n",
       "119997             3.660138             6.617898             8.227812  \n",
       "119998             4.346611             6.420346             8.649150  \n",
       "119999             5.006388             6.573549             7.939662  \n",
       "\n",
       "[120000 rows x 112 columns]"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "jkEsMl2A_9zH",
   "metadata": {
    "id": "jkEsMl2A_9zH"
   },
   "outputs": [],
   "source": [
    "correlation_matrix = selected_features.corr().abs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "yiIzVDw_AA8b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 584
    },
    "id": "yiIzVDw_AA8b",
    "outputId": "b5dc7027-d2da-4af3-c547-41f12b5bd6ae"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Correlation heatmap after removing the high pair correlation features\n",
    "mask = np.triu(np.ones_like(correlation_matrix))\n",
    "dataplot = sns.heatmap(correlation_matrix, mask=mask)\n",
    " \n",
    "# displaying heatmap\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5XVwOI8_CgC-",
   "metadata": {
    "id": "5XVwOI8_CgC-"
   },
   "source": [
    "<h3 style=\"color:rgb(0,120,170)\">PCA Dimensionality Reduction</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "7c1dda3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>zcr_mean</th>\n",
       "      <th>zcr_std</th>\n",
       "      <th>yin_0</th>\n",
       "      <th>raw_melspect_mean_0</th>\n",
       "      <th>raw_melspect_std_0</th>\n",
       "      <th>raw_mfcc_mean_1</th>\n",
       "      <th>raw_mfcc_mean_2</th>\n",
       "      <th>raw_mfcc_mean_3</th>\n",
       "      <th>raw_mfcc_mean_4</th>\n",
       "      <th>raw_mfcc_mean_5</th>\n",
       "      <th>...</th>\n",
       "      <th>cln_mfcc_mean_4</th>\n",
       "      <th>cln_mfcc_mean_5</th>\n",
       "      <th>cln_flatness_mean</th>\n",
       "      <th>cln_flatness_std</th>\n",
       "      <th>cln_centroid_mean</th>\n",
       "      <th>cln_flux_mean</th>\n",
       "      <th>cln_bandwidth_mean</th>\n",
       "      <th>cln_contrast_mean_0</th>\n",
       "      <th>cln_contrast_mean_1</th>\n",
       "      <th>cln_contrast_mean_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.104213</td>\n",
       "      <td>0.025389</td>\n",
       "      <td>144.178635</td>\n",
       "      <td>5.260280</td>\n",
       "      <td>0.678598</td>\n",
       "      <td>11.722803</td>\n",
       "      <td>-2.886116</td>\n",
       "      <td>1.625302</td>\n",
       "      <td>-0.766484</td>\n",
       "      <td>0.358663</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.130756</td>\n",
       "      <td>0.165595</td>\n",
       "      <td>0.235257</td>\n",
       "      <td>0.102272</td>\n",
       "      <td>6887.078613</td>\n",
       "      <td>6.298171</td>\n",
       "      <td>2884.992676</td>\n",
       "      <td>5.941001</td>\n",
       "      <td>5.571944</td>\n",
       "      <td>8.220659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.108329</td>\n",
       "      <td>0.018797</td>\n",
       "      <td>116.932335</td>\n",
       "      <td>6.485734</td>\n",
       "      <td>0.315136</td>\n",
       "      <td>13.808211</td>\n",
       "      <td>-5.056562</td>\n",
       "      <td>2.318141</td>\n",
       "      <td>-0.455920</td>\n",
       "      <td>0.028335</td>\n",
       "      <td>...</td>\n",
       "      <td>0.156415</td>\n",
       "      <td>-0.046879</td>\n",
       "      <td>0.403903</td>\n",
       "      <td>0.094919</td>\n",
       "      <td>5813.555176</td>\n",
       "      <td>9.268286</td>\n",
       "      <td>3186.814941</td>\n",
       "      <td>5.584007</td>\n",
       "      <td>6.089088</td>\n",
       "      <td>7.443485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.203055</td>\n",
       "      <td>0.022426</td>\n",
       "      <td>319.182281</td>\n",
       "      <td>7.089341</td>\n",
       "      <td>0.363829</td>\n",
       "      <td>13.450143</td>\n",
       "      <td>-4.334423</td>\n",
       "      <td>3.202057</td>\n",
       "      <td>-1.927366</td>\n",
       "      <td>0.460847</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.254867</td>\n",
       "      <td>0.380876</td>\n",
       "      <td>0.088798</td>\n",
       "      <td>0.067826</td>\n",
       "      <td>5557.483887</td>\n",
       "      <td>57.868095</td>\n",
       "      <td>2620.215820</td>\n",
       "      <td>4.375466</td>\n",
       "      <td>5.434949</td>\n",
       "      <td>7.736153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.119210</td>\n",
       "      <td>0.032156</td>\n",
       "      <td>256.728058</td>\n",
       "      <td>7.198322</td>\n",
       "      <td>0.459935</td>\n",
       "      <td>13.438527</td>\n",
       "      <td>-5.172253</td>\n",
       "      <td>3.509893</td>\n",
       "      <td>-1.106580</td>\n",
       "      <td>1.211608</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.415970</td>\n",
       "      <td>1.130988</td>\n",
       "      <td>0.262824</td>\n",
       "      <td>0.132288</td>\n",
       "      <td>5596.516113</td>\n",
       "      <td>31.806095</td>\n",
       "      <td>2747.145020</td>\n",
       "      <td>6.926789</td>\n",
       "      <td>6.850839</td>\n",
       "      <td>8.108602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.113839</td>\n",
       "      <td>0.019690</td>\n",
       "      <td>116.983658</td>\n",
       "      <td>7.488858</td>\n",
       "      <td>0.297487</td>\n",
       "      <td>15.132287</td>\n",
       "      <td>-6.222596</td>\n",
       "      <td>2.101814</td>\n",
       "      <td>0.111821</td>\n",
       "      <td>0.178368</td>\n",
       "      <td>...</td>\n",
       "      <td>0.859586</td>\n",
       "      <td>0.031872</td>\n",
       "      <td>0.331669</td>\n",
       "      <td>0.045000</td>\n",
       "      <td>5342.882812</td>\n",
       "      <td>19.879534</td>\n",
       "      <td>3198.522461</td>\n",
       "      <td>6.698604</td>\n",
       "      <td>6.036443</td>\n",
       "      <td>7.433480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119995</th>\n",
       "      <td>0.073382</td>\n",
       "      <td>0.043350</td>\n",
       "      <td>858.709106</td>\n",
       "      <td>5.594575</td>\n",
       "      <td>0.236835</td>\n",
       "      <td>4.621610</td>\n",
       "      <td>-2.240215</td>\n",
       "      <td>2.218656</td>\n",
       "      <td>-4.246311</td>\n",
       "      <td>-2.819625</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.681545</td>\n",
       "      <td>-3.063332</td>\n",
       "      <td>0.068536</td>\n",
       "      <td>0.045667</td>\n",
       "      <td>4001.078125</td>\n",
       "      <td>182.219864</td>\n",
       "      <td>3285.902588</td>\n",
       "      <td>3.968847</td>\n",
       "      <td>6.502321</td>\n",
       "      <td>8.068604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119996</th>\n",
       "      <td>0.026786</td>\n",
       "      <td>0.021679</td>\n",
       "      <td>3544.072021</td>\n",
       "      <td>5.809918</td>\n",
       "      <td>0.225777</td>\n",
       "      <td>3.714819</td>\n",
       "      <td>-3.111917</td>\n",
       "      <td>3.491264</td>\n",
       "      <td>-2.134536</td>\n",
       "      <td>-2.273956</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.555302</td>\n",
       "      <td>-2.513235</td>\n",
       "      <td>0.180928</td>\n",
       "      <td>0.058953</td>\n",
       "      <td>4488.748535</td>\n",
       "      <td>62.407768</td>\n",
       "      <td>3333.172852</td>\n",
       "      <td>4.305187</td>\n",
       "      <td>4.845993</td>\n",
       "      <td>8.952189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119997</th>\n",
       "      <td>0.000837</td>\n",
       "      <td>0.003018</td>\n",
       "      <td>3488.506104</td>\n",
       "      <td>5.712483</td>\n",
       "      <td>0.378321</td>\n",
       "      <td>2.558474</td>\n",
       "      <td>-2.490510</td>\n",
       "      <td>5.043571</td>\n",
       "      <td>-1.124422</td>\n",
       "      <td>-1.422877</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.545844</td>\n",
       "      <td>-1.647332</td>\n",
       "      <td>0.328268</td>\n",
       "      <td>0.037066</td>\n",
       "      <td>4939.418457</td>\n",
       "      <td>21.312246</td>\n",
       "      <td>3299.661377</td>\n",
       "      <td>3.660138</td>\n",
       "      <td>6.617898</td>\n",
       "      <td>8.227812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119998</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2856.960938</td>\n",
       "      <td>5.624564</td>\n",
       "      <td>0.352010</td>\n",
       "      <td>1.487618</td>\n",
       "      <td>-2.024539</td>\n",
       "      <td>4.984841</td>\n",
       "      <td>-1.077376</td>\n",
       "      <td>-0.411108</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.506265</td>\n",
       "      <td>-0.645174</td>\n",
       "      <td>0.302483</td>\n",
       "      <td>0.040981</td>\n",
       "      <td>5235.270020</td>\n",
       "      <td>25.521641</td>\n",
       "      <td>3105.989258</td>\n",
       "      <td>4.346611</td>\n",
       "      <td>6.420346</td>\n",
       "      <td>8.649150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119999</th>\n",
       "      <td>0.009556</td>\n",
       "      <td>0.013782</td>\n",
       "      <td>1049.992798</td>\n",
       "      <td>6.037226</td>\n",
       "      <td>0.719046</td>\n",
       "      <td>1.214382</td>\n",
       "      <td>-1.621043</td>\n",
       "      <td>5.934211</td>\n",
       "      <td>-0.822477</td>\n",
       "      <td>-1.037465</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.233313</td>\n",
       "      <td>-1.268727</td>\n",
       "      <td>0.324750</td>\n",
       "      <td>0.082254</td>\n",
       "      <td>5359.769531</td>\n",
       "      <td>30.723736</td>\n",
       "      <td>3101.273926</td>\n",
       "      <td>5.006388</td>\n",
       "      <td>6.573549</td>\n",
       "      <td>7.939662</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120000 rows × 112 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        zcr_mean   zcr_std        yin_0  raw_melspect_mean_0  \\\n",
       "0       0.104213  0.025389   144.178635             5.260280   \n",
       "1       0.108329  0.018797   116.932335             6.485734   \n",
       "2       0.203055  0.022426   319.182281             7.089341   \n",
       "3       0.119210  0.032156   256.728058             7.198322   \n",
       "4       0.113839  0.019690   116.983658             7.488858   \n",
       "...          ...       ...          ...                  ...   \n",
       "119995  0.073382  0.043350   858.709106             5.594575   \n",
       "119996  0.026786  0.021679  3544.072021             5.809918   \n",
       "119997  0.000837  0.003018  3488.506104             5.712483   \n",
       "119998  0.000000  0.000000  2856.960938             5.624564   \n",
       "119999  0.009556  0.013782  1049.992798             6.037226   \n",
       "\n",
       "        raw_melspect_std_0  raw_mfcc_mean_1  raw_mfcc_mean_2  raw_mfcc_mean_3  \\\n",
       "0                 0.678598        11.722803        -2.886116         1.625302   \n",
       "1                 0.315136        13.808211        -5.056562         2.318141   \n",
       "2                 0.363829        13.450143        -4.334423         3.202057   \n",
       "3                 0.459935        13.438527        -5.172253         3.509893   \n",
       "4                 0.297487        15.132287        -6.222596         2.101814   \n",
       "...                    ...              ...              ...              ...   \n",
       "119995            0.236835         4.621610        -2.240215         2.218656   \n",
       "119996            0.225777         3.714819        -3.111917         3.491264   \n",
       "119997            0.378321         2.558474        -2.490510         5.043571   \n",
       "119998            0.352010         1.487618        -2.024539         4.984841   \n",
       "119999            0.719046         1.214382        -1.621043         5.934211   \n",
       "\n",
       "        raw_mfcc_mean_4  raw_mfcc_mean_5  ...  cln_mfcc_mean_4  \\\n",
       "0             -0.766484         0.358663  ...        -0.130756   \n",
       "1             -0.455920         0.028335  ...         0.156415   \n",
       "2             -1.927366         0.460847  ...        -1.254867   \n",
       "3             -1.106580         1.211608  ...        -0.415970   \n",
       "4              0.111821         0.178368  ...         0.859586   \n",
       "...                 ...              ...  ...              ...   \n",
       "119995        -4.246311        -2.819625  ...        -4.681545   \n",
       "119996        -2.134536        -2.273956  ...        -2.555302   \n",
       "119997        -1.124422        -1.422877  ...        -1.545844   \n",
       "119998        -1.077376        -0.411108  ...        -1.506265   \n",
       "119999        -0.822477        -1.037465  ...        -1.233313   \n",
       "\n",
       "        cln_mfcc_mean_5  cln_flatness_mean  cln_flatness_std  \\\n",
       "0              0.165595           0.235257          0.102272   \n",
       "1             -0.046879           0.403903          0.094919   \n",
       "2              0.380876           0.088798          0.067826   \n",
       "3              1.130988           0.262824          0.132288   \n",
       "4              0.031872           0.331669          0.045000   \n",
       "...                 ...                ...               ...   \n",
       "119995        -3.063332           0.068536          0.045667   \n",
       "119996        -2.513235           0.180928          0.058953   \n",
       "119997        -1.647332           0.328268          0.037066   \n",
       "119998        -0.645174           0.302483          0.040981   \n",
       "119999        -1.268727           0.324750          0.082254   \n",
       "\n",
       "        cln_centroid_mean  cln_flux_mean  cln_bandwidth_mean  \\\n",
       "0             6887.078613       6.298171         2884.992676   \n",
       "1             5813.555176       9.268286         3186.814941   \n",
       "2             5557.483887      57.868095         2620.215820   \n",
       "3             5596.516113      31.806095         2747.145020   \n",
       "4             5342.882812      19.879534         3198.522461   \n",
       "...                   ...            ...                 ...   \n",
       "119995        4001.078125     182.219864         3285.902588   \n",
       "119996        4488.748535      62.407768         3333.172852   \n",
       "119997        4939.418457      21.312246         3299.661377   \n",
       "119998        5235.270020      25.521641         3105.989258   \n",
       "119999        5359.769531      30.723736         3101.273926   \n",
       "\n",
       "        cln_contrast_mean_0  cln_contrast_mean_1  cln_contrast_mean_2  \n",
       "0                  5.941001             5.571944             8.220659  \n",
       "1                  5.584007             6.089088             7.443485  \n",
       "2                  4.375466             5.434949             7.736153  \n",
       "3                  6.926789             6.850839             8.108602  \n",
       "4                  6.698604             6.036443             7.433480  \n",
       "...                     ...                  ...                  ...  \n",
       "119995             3.968847             6.502321             8.068604  \n",
       "119996             4.305187             4.845993             8.952189  \n",
       "119997             3.660138             6.617898             8.227812  \n",
       "119998             4.346611             6.420346             8.649150  \n",
       "119999             5.006388             6.573549             7.939662  \n",
       "\n",
       "[120000 rows x 112 columns]"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "kaaDn8E1DCHJ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "kaaDn8E1DCHJ",
    "outputId": "f7dc1b00-cb3a-4793-b613-28f4e6c770e9"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAeK0lEQVR4nO3de5QdVZ328e9DABEZCJeImIAJGEFUFIjc5JWbMxJAwlIYAyLiLeIQAQdkYNQXmFff5agookjeCCgoklFkaYAswCUXx0Eg4X4JkQyiCWQkIDdBgcDz/lHVejhUn650unK6Tz+ftc46ddlV57c7nfPrXbtqb9kmIiKi3RrdDiAiIoanJIiIiKiUBBEREZWSICIiolISREREVEqCiIiISkkQEcOcpCMl/arbccTokwQRo46k3SVdL+kJSX+U9F+S3t7lmE6V9LykP0l6vIxv10Gc51pJH2sixhh9kiBiVJG0PnAZ8E1gI2A8cBrw7EqeZ82hj47/sL0eMA74FXCJJDXwORG1JEHEaPMGANsX2X7B9p9tX2X7jr4Ckj4uaaGkpyTdI2mHcvsDkv5F0h3A05LWlLRL+df+45Jul7Rny3k2kHSupGWSHpT0BUljBgrQ9vPA+cBrgI3b90vaTdL8sgU0X9Ju5fYvAv8L+FbZEvnWqvygIpIgYrT5DfCCpPMlTZW0YetOSYcApwJHAOsDBwKPthQ5FNgfGAtsClwOfIGiNXIC8BNJ48qy5wMrgNcD2wP/AAx4+UfSK4AjgaW2H2nbt1H5mWdSJI+vAZdL2tj2Z4H/BGbaXs/2zBo/j4h+JUHEqGL7SWB3wMB3gOWS5kratCzyMeDLtue7sNj271pOcabtJbb/DBwOzLM9z/aLtn8OLAD2K883FTjO9tO2Hwa+DkzvEN4/SnocWALsCBxUUWZ/4D7b37e9wvZFwL3Aewb1A4nooInrqBHDmu2FFH+hI2kb4AfAGRStg82B/+5w+JKW5dcBh0hq/XJeC7im3LcWsKylG2GNtuPb/cj24QOE/1rgd23bfkfRlxIxpJIgYlSzfa+k7wGfKDctAbbqdEjL8hLg+7Y/3l5I0mYUHd+b2F4xROECPESRfFptAVxREV/EKsklphhVJG0j6XhJE8r1zSlaDjeURc4BTpC0owqvl9T+hdznB8B7JL1b0hhJ60jaU9IE28uAq4DTJa0vaQ1JW0naYxWrMA94g6TDyk7y9wPbUtyZBfAHYMtV/IwIIAkiRp+ngJ2BGyU9TZEY7gKOB7D9Y+CLwA/Lsj+l6IB+GdtLgGnAvwLLKVoUn+Fv/6+OANYG7gEeAy4GNluV4G0/ChxQxvsocCJwQEtn9jeAgyU9JunMVfmsCGXCoIiIqJIWREREVEqCiIiISkkQERFRKQkiIiIq9dRzEJtssoknTpzY7TAiIkaMm2+++RHb46r29VSCmDhxIgsWLOh2GBERI4ak9ifz/yqXmCIiolISREREVEqCiIiISkkQERFRKQkiIiIqJUFERESlJIiIiKiUBBEREZWSICIiolISRGniSZcz8aTLux1GRMSwkQQRERGVkiAiIqJSEkRERFRKgoiIiEpJEBERUSkJIiIiKiVBREREpSSIiIiolAQRERGVkiAiIqJSEkRERFRKgoiIiEpJEBERUanRBCFpX0mLJC2WdFLF/m0k/VrSs5JOWJljIyKiWY0lCEljgLOAqcC2wKGStm0r9kfgGOCrgzg2IiIa1GQLYidgse37bT8HzAGmtRaw/bDt+cDzK3tsREQ0q8kEMR5Y0rK+tNw2pMdKmiFpgaQFy5cvH1SgERHxck0mCFVs81Afa3u27Sm2p4wbN652cBER0VmTCWIpsHnL+gTgodVwbEREDIEmE8R8YLKkSZLWBqYDc1fDsRERMQTWbOrEtldImglcCYwBzrN9t6Sjyv2zJL0GWACsD7wo6ThgW9tPVh3bVKwREfFyjSUIANvzgHlt22a1LP8PxeWjWsdGRMTqkyepIyKiUhJERERUSoKIiIhKSRAREVEpCSIiIiolQURERKUkiIiIqJQEERERlZIgIiKiUhJERERUSoKIiIhKSRAREVEpCSIiIiolQURERKUkiIiIqDTgfBCS1gI+Cbyz3HQdMMv2800GFhER3VVnwqCzgbWAb5frHyy3faypoCIiovvqJIi3235ry/rVkm5vKqCIiBge6vRBvCBpq74VSVsCLzQXUkREDAd1WhCfAa6RdD8g4HXAhxuNKiIium7ABGH7F5ImA1tTJIh7bT/beGQREdFV/SYISXvbvlrSe9t2bSUJ25c0HFtERHRRpxbEHsDVwHsq9hlIgoiI6GH9Jgjbp5SL/2b7t637JE1qNKqIiOi6Oncx/aRi28VDHUhERAwvnfogtgHeBGzQ1g+xPrBO04FFRER3deqD2Bo4ABjLS/shngI+3mBMERExDHTqg/gZ8DNJu9r+9WqMKSIihoE6D8rdKuloistNf720ZPsjjUUVERFdV6eT+vvAa4B3U4zkOoHiMtOAJO0raZGkxZJOqtgvSWeW+++QtEPLvk9LulvSXZIukpR+j4iI1ahOgni97c8DT9s+H9gfeMtAB0kaA5wFTAW2BQ6VtG1bsanA5PI1g2KUWCSNB44Bpth+MzAGmF6rRhERMSTqJIi+eR8el/RmYANgYo3jdgIW277f9nPAHGBaW5lpwAUu3ACMlbRZuW9N4JWS1gTWBR6q8ZkRETFE6iSI2ZI2BD4HzAXuAf69xnHjgSUt60vLbQOWsf0g8FXg98Ay4AnbV1V9iKQZkhZIWrB8+fIaYUVERB0DJgjb59h+zPYvbW9p+9XAFTXOrarT1SlTJqRpwCTgtcCrJB3eT3yzbU+xPWXcuHE1woqIiDo6JghJu0o6WNKry/XtJP0Q+FWNcy8FNm9Zn8DLLxP1V+ZdwG9tLy+nNr0E2K3GZ0ZExBDpN0FI+gpwHvA+4HJJpwA/B26k6FQeyHxgsqRJktam6GSe21ZmLnBEeTfTLhSXkpZRXFraRdK6kgTsAyxcybpFRMQq6PQcxP7A9rb/Ul7yeQjYzvZ9dU5se4WkmcCVFHchnWf7bklHlftnAfOA/YDFwDOUExHZvlHSxcAtwArgVmD2YCoYERGD0ylB/Nn2XwBsPyZpUd3k0Mf2PIok0LptVsuygaP7OfYU4JSqfRER0bxOCWIrSa2XhCa2rts+sLmwIiKi2zoliPZnFk5vMpCIiBheOg3Wd93qDCQiIoaXOg/KRUTEKJQEERERlWonCEmvajKQiIgYXgZMEJJ2k3QP5YNqkt4q6duNRxYREV1VpwXxdYq5IB4FsH078M4mg4qIiO6rdYnJ9pK2TS80EEtERAwjdaYcXSJpN4pRVtemmMgn4yJFRPS4Oi2IoyiGwxhPMfrq2+hneIyIiOgdA7YgbD8CfGA1xBIREcNInbuYzpc0tmV9Q0nnNRpVRER0XZ1LTNvZfrxvxfZjwPaNRRQREcNCnQSxRjkfBACSNqJe53ZERIxgdb7oTweuLyfwATgE+GJzIUVExHBQp5P6Akk3A3sBAt5r+57GI4uIiK6qe6noXuCxvvKStrD9+8aiioiIrhswQUj6FMXUn3+geIJagIHtmg0tIiK6qU4L4lhga9uPNh1MREQMH3XuYloCPNF0IBERMbzUaUHcD1wr6XLg2b6Ntr/WWFQREdF1dRLE78vX2uUrIiJGgTq3uZ62OgKJiIjhpc5dTOOAE4E3Aev0bbe9d4NxRUREl9XppL6Q4jmIScBpwAPA/AZjioiIYaBOgtjY9rnA87avs/0RYJeG44qIiC6r00n9fPm+TNL+wEPAhOZCioiI4aBOgviCpA2A44FvAusDn240qoiI6LoBLzHZvsz2E7bvsr2X7R1tz61zckn7SlokabGkkyr2S9KZ5f47JO3Qsm+spIsl3StpoaRdV65qERGxKvptQUg60faXJX2TYuyll7B9TKcTSxoDnAX8PcVc1vMlzW0bCXYqMLl87QycXb4DfAO4wvbBktYG1q1frYiIWFWdLjEtLN8XDPLcOwGLbd8PIGkOMA1oTRDTgAtsG7ihbDVsBjwNvBM4EsD2c8Bzg4wjIiIGod8EYfvSshXwZtufGcS5x1OM49RnKX9rHXQqMx5YASwHvivprcDNwLG2n27/EEkzgBkAW2yxxSDCjIiIKh37IGy/AOw4yHOr6pQ1y6wJ7ACcbXt7ihbFy/owyhhn255ie8q4ceMGGWpERLSrcxfTrZLmAj+m+KIGwPYlAxy3FNi8ZX0CxS2ydcoYWGr7xnL7xfSTICIiohl1EsRGwKNA69AaBgZKEPOByZImAQ8C04HD2srMBWaW/RM7A0/YXgYgaYmkrW0vAvbhpX0XERHRsDqD9X14MCe2vULSTOBKYAxwnu27JR1V7p8FzAP2AxYDzwCtn/Up4MLyDqb72/ZFRETD6gzWtw7wUV4+WN9HBjrW9jyKJNC6bVbLsoGj+zn2NmDKQJ8RERHNqDMW0/eB1wDvBq6j6Cd4qsmgIiKi++okiNfb/jzwtO3zgf2BtzQbVkREdFudBNE3WN/jkt4MbABMbCyiiIgYFurcxTRb0obA5ynuOlqvXI6IiB7WaSymeygmC5pj+zGK/octV1dgERHRXZ0uMR1K0Vq4StKNko4rx0mKiIhRoN8EYft22yfb3go4FngdcKOkqyV9fLVFGBERXVGnkxrbN9j+NHAEsCHwrUajioiIrqvzoNzbKS43vQ94AJhNMS5TRET0sE6d1P8XeD/wGDAHeIftpasrsIiI6K5OLYhngam2f7O6gomIiOGj04RBp63OQCIiYnip1UkdERGjTxJERERU6tRJvUOnA23fMvThRETEcNGpk/r08n0dinkZbqeYQ3o74EZg92ZDi4iIbur0JPVetvcCfgfsYHuK7R2B7SlmgIuIiB5Wpw9iG9t39q3Yvgt4W2MRRUTEsFBnuO+Fks4BfgAYOBxY2GhUERHRdXUSxIeBT1IM2AfwS+DsxiKKiIhhYcAEYfsvkmYB82wvWg0xRUTEMDBgH4SkA4HbgCvK9bdJmttwXBER0WV1OqlPAXYCHgewfRs9Pif1xJMuZ+JJl3c7jIiIrqqTIFbYfqLxSCIiYlip00l9l6TDgDGSJgPHANc3G1ZERHRbnRbEp4A3UQz/fRHwJHBcgzFFRMQwUOcupmeAz5aviIgYJepMOfoG4ASKjum/lre9d3NhRUREt9Xpg/gxMAs4B3ih2XAiImK4qHsX09m2b7J9c9+rzskl7StpkaTFkk6q2C9JZ5b772gfYlzSGEm3SrqsZn0iImKI1EkQl0r6J0mbSdqo7zXQQZLGAGcBU4FtgUMlbdtWbCowuXzN4OVDeBxLxn2KiOiKOgniQ8BnKG5tvbl8Lahx3E7AYtv3234OmANMayszDbjAhRuAsZI2A5A0Adif4tJWRESsZnXuYpo0yHOPB5a0rC8Fdq5RZjywDDgDOBH4u04fImkGReuDLbbYYpChRkREu05Tju5t+2pJ763ab/uSAc6tqsPqlJF0APCw7Zsl7dnpQ2zPBmYDTJkypf38ERExSJ1aEHsAVwPvqdhnYKAEsRTYvGV9AvBQzTIHAwdK2o9iytP1Jf3A9uEDfGZERAyRfhOE7VPK9w8P8tzzgcmSJgEPAtOBw9rKzAVmSppDcfnpCdvLgJPLF2UL4oQkh4iI1avOcxBI2p9iuI11+rbZ/rdOx9heIWkmcCUwBjjP9t2Sjir3zwLmAftRzHH9DMXkRBERMQzUeZJ6FrAusBfFHUUHAzfVObnteRRJoHXbrJZlA0cPcI5rgWvrfF5ERAydOre57mb7COAx26cBu/LSfoOelXkhImI0q5Mg/ly+PyPptcDzwGBvfY2IiBGiTh/EZZLGAl8BbqG4gykPr0VE9Lg6D8r9n3LxJ+WYSOtkhrmIiN7X6UG5ygfkyn11HpSLiIgRrFMLouoBuT51HpSLiIgRrNODcnkmISJiFBvwLiZJG5dzNtwi6WZJ35C08eoILiIiuqfOba5zgOXA+ygeklsO/EeTQUVERPfVuc11o5Y7mQC+IOmghuKJiIhhok4L4hpJ0yWtUb7+EcjjxRERPa5OgvgE8EPg2fI1B/hnSU9JerLJ4CIionvqPCjXcUa3iIjoTXXuYvpo2/oYSac0F1JERAwHdS4x7SNpnqTNJL0FuIEB5omOiIiRr84lpsMkvR+4k2JSn0Nt/1fjkUVERFfVucQ0GTgW+AnwAPBBSes2HFdERHRZnUtMlwKft/0JYA/gPor5pkeVTB4UEaNNnQfldrL9JPx1itDTJc1tNqyIiOi2flsQkk4EsP2kpEPadmcgv4iIHtfpEtP0luWT2/bt20AsI0YuN0XEaNApQaif5ar1iIjoMZ0ShPtZrlqPiIge06mT+q3lWEsCXtky7pKAdRqPLCIiuqrTjHJjVmcgI1FrP8QDX9q/i5FERAy9Os9BRETEKJQEMURyZ1NE9JokiIiIqJQEERERlRpNEJL2lbRI0mJJJ1Xsl6Qzy/13SNqh3L65pGskLZR0t6Rjm4wzIiJerrEEIWkMcBYwFdgWOFTStm3FpgKTy9cM4Oxy+wrgeNtvBHYBjq44dthKf0RE9IImWxA7AYtt32/7OYq5rKe1lZkGXODCDcBYSZvZXmb7FgDbTwELgfENxhoREW2aTBDjgSUt60t5+Zf8gGUkTQS2B26s+hBJMyQtkLRg+fLlqxpzRESUmkwQVeM1tQ/R0bGMpPUoJio6rm/I8ZcVtmfbnmJ7yrhx4wYdbEREvFSTCWIpsHnL+gTgobplJK1FkRwutH1Jg3FGRESFJhPEfGCypEmS1qYYPrx9oqG5wBHl3Uy7AE/YXiZJwLnAQttfazDGxqXDOiJGqjozyg2K7RWSZgJXAmOA82zfLemocv8sYB6wH7AYeIa/TUT0DuCDwJ2Sbiu3/avteU3F27S+JJExmyJipGgsQQCUX+jz2rbNalk2cHTFcb+ih+ecaE0WSRwRMVzlSeqIiKiUBBEREZUavcQU9VV1ZOeyU0R0U1oQw1zugoqIbkmCiIiISkkQERFRKQliBMnlpohYndJJPQK1Jol0ZEdEU9KCGOHSqoiIpqQF0UOqntDuk5ZGRKystCBGkdbWRloeETGQtCBGufRnRER/0oKIv0oLIyJapQURA6rqz8gotBG9LwkiVlmnlkaSScTIlQQRq1WSScTIkQQRw9ZAl7aSTCKalQQRI15/Q6UngUSsmiSIGBXqtkaqJMHEaJUEEVFDkkmMRkkQEUMsQ55Er0iCiFjN0hqJkSIJImIYG6g1kru6oklJEBE9ps5dXWm5RB1JEBHxMmm5BCRBRMQQGUzLpU7LJomne5IgImJY66+1sjLDtmTAycFJgoiIUS/JploSRETEEOqlASkbTRCS9gW+AYwBzrH9pbb9KvfvBzwDHGn7ljrHRkSMdMM9mTSWICSNAc4C/h5YCsyXNNf2PS3FpgKTy9fOwNnAzjWPjYgYNbrxVH6TU47uBCy2fb/t54A5wLS2MtOAC1y4ARgrabOax0ZEjGpNTw0s282cWDoY2Nf2x8r1DwI7257ZUuYy4Eu2f1Wu/wL4F2DiQMe2nGMGMKNc3RpYtJKhbgI8spLHjBS9WrderRf0bt1Sr+HrdbbHVe1osg9CFdvas1F/ZeocW2y0ZwOzVy60lgCkBbanDPb44axX69ar9YLerVvqNTI1mSCWApu3rE8AHqpZZu0ax0ZERIOa7IOYD0yWNEnS2sB0YG5bmbnAESrsAjxhe1nNYyMiokGNtSBsr5A0E7iS4lbV82zfLemocv8sYB7FLa6LKW5z/XCnYxsKddCXp0aAXq1br9YLerduqdcI1FgndUREjGxNXmKKiIgRLAkiIiIqjeoEIWlfSYskLZZ0UrfjGSxJm0u6RtJCSXdLOrbcvpGkn0u6r3zfsNuxDoakMZJuLZ+b6aV6jZV0saR7y3+7XXuhbpI+Xf4e3iXpIknrjNR6STpP0sOS7mrZ1m9dJJ1cfp8skvTu7kQ9dEZtgmgZzmMqsC1wqKRtuxvVoK0Ajrf9RmAX4OiyLicBv7A9GfhFuT4SHQssbFnvlXp9A7jC9jbAWynqOKLrJmk8cAwwxfabKW4ymc7Irdf3gH3btlXWpfw/Nx14U3nMt8vvmRFr1CYIemg4D9vL+gY5tP0UxRfNeIr6nF8WOx84qCsBrgJJE4D9gXNaNvdCvdYH3gmcC2D7OduP0wN1o7g78pWS1gTWpXiGaUTWy/YvgT+2be6vLtOAObaftf1birszd1odcTZlNCeI8cCSlvWl5bYRTdJEYHvgRmDT8rkSyvdXdzG0wToDOBF4sWVbL9RrS2A58N3y8tk5kl7FCK+b7QeBrwK/B5ZRPNt0FSO8Xm36q0vPfaeM5gRReziPkULSesBPgONsP9nteFaVpAOAh23f3O1YGrAmsANwtu3tgacZOZdd+lVej58GTAJeC7xK0uHdjWq16bnvlNGcIOoMBTJiSFqLIjlcaPuScvMfytFxKd8f7lZ8g/QO4EBJD1BcAtxb0g8Y+fWC4vdvqe0by/WLKRLGSK/bu4Df2l5u+3ngEmA3Rn69WvVXl576ToHRnSB6ZjiPcuKlc4GFtr/Wsmsu8KFy+UPAz1Z3bKvC9sm2J9ieSPHvc7Xtwxnh9QKw/T/AEklbl5v2Ae5h5Nft98AuktYtfy/3oegTG+n1atVfXeYC0yW9QtIkinlubupCfEPH9qh9UQzz8Rvgv4HPdjueVajH7hRN2TuA28rXfsDGFHdZ3Fe+b9TtWFehjnsCl5XLPVEv4G3AgvLf7afAhr1QN+A04F7gLuD7wCtGar2Aiyj6Up6naCF8tFNdgM+W3yeLgKndjn9VXxlqIyIiKo3mS0wREdFBEkRERFRKgoiIiEpJEBERUSkJIiIiKiVBRFdJsqTTW9ZPkHTqEJ37e5IOHopzDfA5h5SjsV5Tse8NkuaVI3wulPQjSZs2HVOTJB00gge2jJWQBBHd9izwXkmbdDuQVis5CudHgX+yvVfbOdYBLqcYTuP1LkbbPRsYN3SRdsVBFCMgR49LgohuW0Exr++n23e0twAk/al831PSdeVf47+R9CVJH5B0k6Q7JW3Vcpp3SfrPstwB5fFjJH1F0nxJd0j6RMt5r5H0Q+DOingOLc9/l6R/L7f9b4oHFWdJ+krbIYcBv7Z9ad8G29fYvqucI+G75flulbRXeb4jJf1U0qWSfitppqR/LsvcIGmjsty1ks6QdH0Zz07l9o3K4+8oy29Xbj+1nNvgWkn3SzqmpV6Hlz+72yT9v77kKOlPkr4o6fbyXJtK2g04EPhKWX4rScdIuqf8zDl1/tFjhOj2k3p5je4X8CdgfeABYAPgBODUct/3gINby5bvewKPA5tRPKX7IHBaue9Y4IyW46+g+ENoMsWTsOsAM4DPlWVeQfE086TyvE8DkyrifC3FMBLjKAbauxo4qNx3LcX8B+3HfA04tp96Hw98t1zepjz3OsCRFMNE/135WU8AR5Xlvk4xEGPfZ36nXH4ncFe5/E3glHJ5b+C2cvlU4PqyvpsAjwJrAW8ELgXWKst9GziiXDbwnnL5yy0/s/Z/l4eAV5TLY7v9O5XX0L3SgoiuczHy7AUUE83UNd/FPBjPUgxtcFW5/U5gYku5H9l+0fZ9wP0UX8b/ABwh6TaKYdE3pkggADe5GMu/3duBa10MQrcCuJDii3mwdqcYhgLb9wK/A95Q7rvG9lO2l1MkiL4WSHvdLiqP/yWwvqSxbee9GthY0gZl+ctdzFXwCMUAc5tSjJW0IzC//HnsQzEUOcBzwGXl8s1tn93qDuDCctTWFSvzQ4jhbc1uBxBROgO4Bfhuy7YVlJdBy4Hf1m7Z92zL8ost6y/y0t/r9rFkTDEs86dsX9m6Q9KeFC2IKlVDOQ/kbmCPQZxvVevWrq9c63lfKM8l4HzbJ1cc97xtt5Wvsj9FsjwQ+LykN5VJNEa4tCBiWLD9R+BHFB2+fR6g+OsWijkG1hrEqQ+RtEbZL7ElxSBqVwKfVDFEet+dRq8a4Dw3AntI2qS8Rn8ocN0Ax/wQ2E3S/n0bVMyD/hbgl8AH+j4f2KKMbWW8vzx+d4qJeZ5oO++ewCPuPDfIL4CDJb26PGYjSa8b4HOforgEhqQ1gM1tX0MxsdNYYL2VrEcMU2lBxHByOjCzZf07wM8k3UTxRdbfX/edLKL4It+U4lr+XySdQ3G55JayZbKcAabAtL1M0snANRR/dc+z3XHIatt/LjvGz5B0BsWIoHdQ9JN8m6Jj+06KltKRtp8twqntMUnXU/ThfKTcdirFLHV3AM/wt2Gp+4vxHkmfA64qv+yfB46muOTVnznAd8qO7unAueVlLAFfdzF1avSAjOYaMQJJuhY4wfaCbscSvSuXmCIiolJaEBERUSktiIiIqJQEERERlZIgIiKiUhJERERUSoKIiIhK/x+HxJA1nbf99AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "features_scaled = scaler.fit_transform(selected_features)\n",
    "\n",
    "# Perform PCA on the scaled data\n",
    "pca = PCA()\n",
    "pca.fit(features_scaled)\n",
    "\n",
    "# Get the explained variance ratios\n",
    "explained_variances = pca.explained_variance_ratio_\n",
    "\n",
    "# Create the scree plot\n",
    "component_numbers = np.arange(1, len(explained_variances) + 1)\n",
    "plt.bar(component_numbers, explained_variances)\n",
    "plt.xlabel('Number of Components')\n",
    "plt.ylabel('Explained Variance Ratio')\n",
    "plt.title('Scree Plot')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "ZlJh23JGHy78",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZlJh23JGHy78",
    "outputId": "ed6edad5-c443-4cd7-ab82-0cc7aeae934e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cumulative explained variance with 80 components: 0.9194094683605681\n"
     ]
    }
   ],
   "source": [
    "num_components = 80\n",
    "\n",
    "# Calculate the cumulative explained variance up to the selected number of components\n",
    "cumulative_variance = np.cumsum(explained_variances)[:num_components]\n",
    "\n",
    "# Print the cumulative explained variance\n",
    "print(f\"Cumulative explained variance with {num_components} components: {cumulative_variance[-1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "ZdtFD-W7IbFQ",
   "metadata": {
    "id": "ZdtFD-W7IbFQ"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#Borrowed PCA analysis results from Abel\n",
    "pca = PCA(n_components = 80)\n",
    "\n",
    "features_pca = pca.fit_transform(features_scaled)\n",
    "\n",
    "# Split the data into a training set and a test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_pca, labels.iloc[:, 0], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "22bdddcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>70</th>\n",
       "      <th>71</th>\n",
       "      <th>72</th>\n",
       "      <th>73</th>\n",
       "      <th>74</th>\n",
       "      <th>75</th>\n",
       "      <th>76</th>\n",
       "      <th>77</th>\n",
       "      <th>78</th>\n",
       "      <th>79</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.791994</td>\n",
       "      <td>3.303306</td>\n",
       "      <td>-0.246607</td>\n",
       "      <td>-0.375513</td>\n",
       "      <td>0.405586</td>\n",
       "      <td>1.033834</td>\n",
       "      <td>1.051862</td>\n",
       "      <td>-0.822095</td>\n",
       "      <td>4.353235</td>\n",
       "      <td>2.450005</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.055442</td>\n",
       "      <td>-0.449363</td>\n",
       "      <td>0.304789</td>\n",
       "      <td>-0.188203</td>\n",
       "      <td>0.868141</td>\n",
       "      <td>0.380718</td>\n",
       "      <td>0.331418</td>\n",
       "      <td>0.718659</td>\n",
       "      <td>-1.198744</td>\n",
       "      <td>-1.385343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.097101</td>\n",
       "      <td>1.781492</td>\n",
       "      <td>-1.007008</td>\n",
       "      <td>0.727873</td>\n",
       "      <td>1.325819</td>\n",
       "      <td>0.476383</td>\n",
       "      <td>-0.860520</td>\n",
       "      <td>0.237922</td>\n",
       "      <td>-0.973739</td>\n",
       "      <td>-0.128043</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.576434</td>\n",
       "      <td>-0.160582</td>\n",
       "      <td>0.302548</td>\n",
       "      <td>-0.514086</td>\n",
       "      <td>-0.306393</td>\n",
       "      <td>0.045350</td>\n",
       "      <td>1.300630</td>\n",
       "      <td>0.601145</td>\n",
       "      <td>-0.077597</td>\n",
       "      <td>0.405348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.219244</td>\n",
       "      <td>2.916082</td>\n",
       "      <td>-1.762921</td>\n",
       "      <td>0.174914</td>\n",
       "      <td>0.211064</td>\n",
       "      <td>0.105094</td>\n",
       "      <td>0.824574</td>\n",
       "      <td>-0.478362</td>\n",
       "      <td>1.308570</td>\n",
       "      <td>2.099804</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.026012</td>\n",
       "      <td>-0.500549</td>\n",
       "      <td>0.654002</td>\n",
       "      <td>-0.962585</td>\n",
       "      <td>0.816004</td>\n",
       "      <td>0.129345</td>\n",
       "      <td>0.489542</td>\n",
       "      <td>0.566647</td>\n",
       "      <td>-0.036291</td>\n",
       "      <td>0.547426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.018039</td>\n",
       "      <td>0.863435</td>\n",
       "      <td>-1.183302</td>\n",
       "      <td>-0.909812</td>\n",
       "      <td>1.518788</td>\n",
       "      <td>1.088019</td>\n",
       "      <td>-1.939883</td>\n",
       "      <td>0.270709</td>\n",
       "      <td>-1.363617</td>\n",
       "      <td>-1.718436</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.974792</td>\n",
       "      <td>-0.324941</td>\n",
       "      <td>-0.076297</td>\n",
       "      <td>-0.603342</td>\n",
       "      <td>0.627985</td>\n",
       "      <td>-0.830068</td>\n",
       "      <td>1.648715</td>\n",
       "      <td>0.068747</td>\n",
       "      <td>-0.608866</td>\n",
       "      <td>1.715496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.536368</td>\n",
       "      <td>0.197603</td>\n",
       "      <td>-1.544138</td>\n",
       "      <td>0.634512</td>\n",
       "      <td>1.611416</td>\n",
       "      <td>-1.689236</td>\n",
       "      <td>0.284575</td>\n",
       "      <td>0.396129</td>\n",
       "      <td>0.074410</td>\n",
       "      <td>-1.077665</td>\n",
       "      <td>...</td>\n",
       "      <td>0.814909</td>\n",
       "      <td>-0.258374</td>\n",
       "      <td>-0.836995</td>\n",
       "      <td>0.311952</td>\n",
       "      <td>-0.207761</td>\n",
       "      <td>-1.736649</td>\n",
       "      <td>-0.485814</td>\n",
       "      <td>-0.124139</td>\n",
       "      <td>-0.717673</td>\n",
       "      <td>0.717474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119995</th>\n",
       "      <td>6.933061</td>\n",
       "      <td>0.223553</td>\n",
       "      <td>0.581143</td>\n",
       "      <td>3.901134</td>\n",
       "      <td>-0.767832</td>\n",
       "      <td>-2.387336</td>\n",
       "      <td>1.327399</td>\n",
       "      <td>0.092358</td>\n",
       "      <td>-0.499150</td>\n",
       "      <td>1.285040</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.007032</td>\n",
       "      <td>0.294635</td>\n",
       "      <td>0.890607</td>\n",
       "      <td>-0.581983</td>\n",
       "      <td>0.832344</td>\n",
       "      <td>1.621503</td>\n",
       "      <td>-0.344453</td>\n",
       "      <td>-0.412634</td>\n",
       "      <td>-0.993342</td>\n",
       "      <td>-2.612158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119996</th>\n",
       "      <td>4.288282</td>\n",
       "      <td>-1.342496</td>\n",
       "      <td>-0.756865</td>\n",
       "      <td>1.889423</td>\n",
       "      <td>-1.076122</td>\n",
       "      <td>-3.048436</td>\n",
       "      <td>-0.557106</td>\n",
       "      <td>0.130120</td>\n",
       "      <td>-0.900682</td>\n",
       "      <td>-0.725595</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.216709</td>\n",
       "      <td>0.531755</td>\n",
       "      <td>0.774312</td>\n",
       "      <td>0.380048</td>\n",
       "      <td>-0.407169</td>\n",
       "      <td>1.562379</td>\n",
       "      <td>0.362743</td>\n",
       "      <td>-0.745699</td>\n",
       "      <td>-0.886617</td>\n",
       "      <td>-1.195036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119997</th>\n",
       "      <td>0.540718</td>\n",
       "      <td>-1.093760</td>\n",
       "      <td>-1.308527</td>\n",
       "      <td>1.710420</td>\n",
       "      <td>-0.140204</td>\n",
       "      <td>-1.786093</td>\n",
       "      <td>-0.897580</td>\n",
       "      <td>-2.366068</td>\n",
       "      <td>-1.233963</td>\n",
       "      <td>-0.139652</td>\n",
       "      <td>...</td>\n",
       "      <td>0.259619</td>\n",
       "      <td>0.129081</td>\n",
       "      <td>0.248048</td>\n",
       "      <td>0.496854</td>\n",
       "      <td>0.371112</td>\n",
       "      <td>-0.659888</td>\n",
       "      <td>-0.963302</td>\n",
       "      <td>1.541924</td>\n",
       "      <td>-0.466720</td>\n",
       "      <td>-0.624517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119998</th>\n",
       "      <td>3.679487</td>\n",
       "      <td>0.156296</td>\n",
       "      <td>-1.274762</td>\n",
       "      <td>1.025832</td>\n",
       "      <td>0.103076</td>\n",
       "      <td>-1.117082</td>\n",
       "      <td>1.307523</td>\n",
       "      <td>-1.713429</td>\n",
       "      <td>0.188170</td>\n",
       "      <td>0.920887</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.310104</td>\n",
       "      <td>-0.471654</td>\n",
       "      <td>0.432249</td>\n",
       "      <td>-0.564854</td>\n",
       "      <td>0.690129</td>\n",
       "      <td>1.195555</td>\n",
       "      <td>-0.229659</td>\n",
       "      <td>-0.609314</td>\n",
       "      <td>-0.521974</td>\n",
       "      <td>0.428313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119999</th>\n",
       "      <td>2.888836</td>\n",
       "      <td>0.663419</td>\n",
       "      <td>-1.031527</td>\n",
       "      <td>-0.235095</td>\n",
       "      <td>1.135663</td>\n",
       "      <td>-0.420753</td>\n",
       "      <td>-1.882425</td>\n",
       "      <td>-1.266466</td>\n",
       "      <td>0.188927</td>\n",
       "      <td>0.274841</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.158064</td>\n",
       "      <td>-1.045302</td>\n",
       "      <td>-1.442180</td>\n",
       "      <td>2.003965</td>\n",
       "      <td>0.118290</td>\n",
       "      <td>-0.460954</td>\n",
       "      <td>1.245854</td>\n",
       "      <td>0.039873</td>\n",
       "      <td>0.461614</td>\n",
       "      <td>0.057619</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120000 rows × 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1         2         3         4         5         6   \\\n",
       "0       1.791994  3.303306 -0.246607 -0.375513  0.405586  1.033834  1.051862   \n",
       "1       0.097101  1.781492 -1.007008  0.727873  1.325819  0.476383 -0.860520   \n",
       "2       6.219244  2.916082 -1.762921  0.174914  0.211064  0.105094  0.824574   \n",
       "3       2.018039  0.863435 -1.183302 -0.909812  1.518788  1.088019 -1.939883   \n",
       "4       0.536368  0.197603 -1.544138  0.634512  1.611416 -1.689236  0.284575   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "119995  6.933061  0.223553  0.581143  3.901134 -0.767832 -2.387336  1.327399   \n",
       "119996  4.288282 -1.342496 -0.756865  1.889423 -1.076122 -3.048436 -0.557106   \n",
       "119997  0.540718 -1.093760 -1.308527  1.710420 -0.140204 -1.786093 -0.897580   \n",
       "119998  3.679487  0.156296 -1.274762  1.025832  0.103076 -1.117082  1.307523   \n",
       "119999  2.888836  0.663419 -1.031527 -0.235095  1.135663 -0.420753 -1.882425   \n",
       "\n",
       "              7         8         9   ...        70        71        72  \\\n",
       "0      -0.822095  4.353235  2.450005  ... -0.055442 -0.449363  0.304789   \n",
       "1       0.237922 -0.973739 -0.128043  ... -0.576434 -0.160582  0.302548   \n",
       "2      -0.478362  1.308570  2.099804  ... -0.026012 -0.500549  0.654002   \n",
       "3       0.270709 -1.363617 -1.718436  ... -0.974792 -0.324941 -0.076297   \n",
       "4       0.396129  0.074410 -1.077665  ...  0.814909 -0.258374 -0.836995   \n",
       "...          ...       ...       ...  ...       ...       ...       ...   \n",
       "119995  0.092358 -0.499150  1.285040  ... -1.007032  0.294635  0.890607   \n",
       "119996  0.130120 -0.900682 -0.725595  ... -0.216709  0.531755  0.774312   \n",
       "119997 -2.366068 -1.233963 -0.139652  ...  0.259619  0.129081  0.248048   \n",
       "119998 -1.713429  0.188170  0.920887  ... -0.310104 -0.471654  0.432249   \n",
       "119999 -1.266466  0.188927  0.274841  ... -0.158064 -1.045302 -1.442180   \n",
       "\n",
       "              73        74        75        76        77        78        79  \n",
       "0      -0.188203  0.868141  0.380718  0.331418  0.718659 -1.198744 -1.385343  \n",
       "1      -0.514086 -0.306393  0.045350  1.300630  0.601145 -0.077597  0.405348  \n",
       "2      -0.962585  0.816004  0.129345  0.489542  0.566647 -0.036291  0.547426  \n",
       "3      -0.603342  0.627985 -0.830068  1.648715  0.068747 -0.608866  1.715496  \n",
       "4       0.311952 -0.207761 -1.736649 -0.485814 -0.124139 -0.717673  0.717474  \n",
       "...          ...       ...       ...       ...       ...       ...       ...  \n",
       "119995 -0.581983  0.832344  1.621503 -0.344453 -0.412634 -0.993342 -2.612158  \n",
       "119996  0.380048 -0.407169  1.562379  0.362743 -0.745699 -0.886617 -1.195036  \n",
       "119997  0.496854  0.371112 -0.659888 -0.963302  1.541924 -0.466720 -0.624517  \n",
       "119998 -0.564854  0.690129  1.195555 -0.229659 -0.609314 -0.521974  0.428313  \n",
       "119999  2.003965  0.118290 -0.460954  1.245854  0.039873  0.461614  0.057619  \n",
       "\n",
       "[120000 rows x 80 columns]"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_features1 = pd.DataFrame(features_pca)\n",
    "selected_features1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31122a42",
   "metadata": {},
   "source": [
    "<h3 style=\"color:rgb(0,120,170)\">Low Feature-Label Correlation Dimensionality Reduction</h3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "3453f793",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.011298</td>\n",
       "      <td>-0.011726</td>\n",
       "      <td>-0.012995</td>\n",
       "      <td>-0.016310</td>\n",
       "      <td>-0.017446</td>\n",
       "      <td>-0.007461</td>\n",
       "      <td>-0.004392</td>\n",
       "      <td>0.003491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.010148</td>\n",
       "      <td>0.029310</td>\n",
       "      <td>0.024684</td>\n",
       "      <td>0.013365</td>\n",
       "      <td>0.008537</td>\n",
       "      <td>0.014405</td>\n",
       "      <td>0.007089</td>\n",
       "      <td>-0.021881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.073404</td>\n",
       "      <td>0.085572</td>\n",
       "      <td>0.079991</td>\n",
       "      <td>0.066851</td>\n",
       "      <td>0.068402</td>\n",
       "      <td>0.084497</td>\n",
       "      <td>0.064565</td>\n",
       "      <td>0.038306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.000452</td>\n",
       "      <td>-0.011425</td>\n",
       "      <td>-0.009952</td>\n",
       "      <td>0.000451</td>\n",
       "      <td>-0.002836</td>\n",
       "      <td>-0.011905</td>\n",
       "      <td>-0.013502</td>\n",
       "      <td>-0.026167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.002387</td>\n",
       "      <td>-0.006452</td>\n",
       "      <td>-0.004037</td>\n",
       "      <td>-0.000473</td>\n",
       "      <td>-0.004615</td>\n",
       "      <td>-0.006617</td>\n",
       "      <td>-0.017067</td>\n",
       "      <td>-0.011390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>-0.011600</td>\n",
       "      <td>-0.015438</td>\n",
       "      <td>-0.010265</td>\n",
       "      <td>-0.009187</td>\n",
       "      <td>-0.013764</td>\n",
       "      <td>-0.012778</td>\n",
       "      <td>-0.005238</td>\n",
       "      <td>-0.014093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>0.003296</td>\n",
       "      <td>0.012277</td>\n",
       "      <td>0.005726</td>\n",
       "      <td>0.002248</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>0.002186</td>\n",
       "      <td>0.012464</td>\n",
       "      <td>-0.001419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>0.001984</td>\n",
       "      <td>0.002071</td>\n",
       "      <td>0.002715</td>\n",
       "      <td>0.003476</td>\n",
       "      <td>0.004582</td>\n",
       "      <td>0.006021</td>\n",
       "      <td>0.009349</td>\n",
       "      <td>-0.007145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>-0.001047</td>\n",
       "      <td>0.002506</td>\n",
       "      <td>-0.006637</td>\n",
       "      <td>-0.001275</td>\n",
       "      <td>-0.004733</td>\n",
       "      <td>0.000755</td>\n",
       "      <td>0.001649</td>\n",
       "      <td>-0.008907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>0.003141</td>\n",
       "      <td>-0.005862</td>\n",
       "      <td>0.004661</td>\n",
       "      <td>-0.003429</td>\n",
       "      <td>0.004874</td>\n",
       "      <td>0.005609</td>\n",
       "      <td>0.007523</td>\n",
       "      <td>0.003461</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5         6  \\\n",
       "0  -0.011298 -0.011726 -0.012995 -0.016310 -0.017446 -0.007461 -0.004392   \n",
       "1   0.010148  0.029310  0.024684  0.013365  0.008537  0.014405  0.007089   \n",
       "2   0.073404  0.085572  0.079991  0.066851  0.068402  0.084497  0.064565   \n",
       "3  -0.000452 -0.011425 -0.009952  0.000451 -0.002836 -0.011905 -0.013502   \n",
       "4  -0.002387 -0.006452 -0.004037 -0.000473 -0.004615 -0.006617 -0.017067   \n",
       "..       ...       ...       ...       ...       ...       ...       ...   \n",
       "75 -0.011600 -0.015438 -0.010265 -0.009187 -0.013764 -0.012778 -0.005238   \n",
       "76  0.003296  0.012277  0.005726  0.002248  0.001200  0.002186  0.012464   \n",
       "77  0.001984  0.002071  0.002715  0.003476  0.004582  0.006021  0.009349   \n",
       "78 -0.001047  0.002506 -0.006637 -0.001275 -0.004733  0.000755  0.001649   \n",
       "79  0.003141 -0.005862  0.004661 -0.003429  0.004874  0.005609  0.007523   \n",
       "\n",
       "           7  \n",
       "0   0.003491  \n",
       "1  -0.021881  \n",
       "2   0.038306  \n",
       "3  -0.026167  \n",
       "4  -0.011390  \n",
       "..       ...  \n",
       "75 -0.014093  \n",
       "76 -0.001419  \n",
       "77 -0.007145  \n",
       "78 -0.008907  \n",
       "79  0.003461  \n",
       "\n",
       "[80 rows x 8 columns]"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine features_pca and labels\n",
    "combined_data = pd.concat([selected_features1, labels], axis=1)\n",
    "\n",
    "# Calculate correlation matrix\n",
    "correlation_matrix = combined_data.corr()\n",
    "\n",
    "# Filter the correlation matrix for correlations with labels\n",
    "label_correlations = correlation_matrix.iloc[:-8, -8:]\n",
    "label_correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "5c7ddfe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     0.010640\n",
      "1     0.016177\n",
      "2     0.070198\n",
      "3     0.009586\n",
      "4     0.006630\n",
      "        ...   \n",
      "75    0.011545\n",
      "76    0.005102\n",
      "77    0.004668\n",
      "78    0.003439\n",
      "79    0.004820\n",
      "Length: 80, dtype: float64\n",
      "Int64Index([ 0,  1,  2,  5,  6,  7, 11, 12, 14, 16, 19, 20, 21, 22, 23, 24, 25,\n",
      "            27, 45, 52, 55, 60, 71, 73, 75],\n",
      "           dtype='int64')\n"
     ]
    }
   ],
   "source": [
    "# Calculate the average correlation for each row\n",
    "average_correlation = label_correlations.abs().mean(axis=1)\n",
    "print(average_correlation)\n",
    "# Filter rows with an average correlation below 0.7\n",
    "selected_feat = label_correlations[average_correlation >= 0.01].index\n",
    "print(selected_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "2b75bcd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum average correlation: 0.0012229148386942669\n",
      "Maximum average correlation: 0.0701984249362977\n"
     ]
    }
   ],
   "source": [
    "min_corr = average_correlation.min()\n",
    "max_corr = average_correlation.max()\n",
    "\n",
    "print(\"Minimum average correlation:\", min_corr)\n",
    "print(\"Maximum average correlation:\", max_corr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "c10e52e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the average_correlation values\n",
    "plt.bar(average_correlation.index, average_correlation.values)\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Average Correlation')\n",
    "plt.title('Average Correlation of Features')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "95ff98d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of values above 0.01:  25\n"
     ]
    }
   ],
   "source": [
    "above_threshold = average_correlation[average_correlation > 0.01]\n",
    "count_above_threshold = len(above_threshold)\n",
    "print(\"Number of values above 0.01: \", count_above_threshold)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "909abb86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows with average correlation above 0.01:\n",
      "[0, 1, 2, 5, 6, 7, 11, 12, 14, 16, 19, 20, 21, 22, 23, 24, 25, 27, 45, 52, 55, 60, 71, 73, 75]\n"
     ]
    }
   ],
   "source": [
    "above_threshold = average_correlation[average_correlation > 0.01]\n",
    "rows_above_threshold = above_threshold.index.tolist()\n",
    "print(\"Rows with average correlation above 0.01:\")\n",
    "print(rows_above_threshold)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "d12ef4f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>14</th>\n",
       "      <th>16</th>\n",
       "      <th>...</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>27</th>\n",
       "      <th>45</th>\n",
       "      <th>52</th>\n",
       "      <th>55</th>\n",
       "      <th>60</th>\n",
       "      <th>71</th>\n",
       "      <th>73</th>\n",
       "      <th>75</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.791994</td>\n",
       "      <td>3.303306</td>\n",
       "      <td>-0.246607</td>\n",
       "      <td>1.033834</td>\n",
       "      <td>1.051862</td>\n",
       "      <td>-0.822095</td>\n",
       "      <td>-1.564288</td>\n",
       "      <td>3.893851</td>\n",
       "      <td>-1.970771</td>\n",
       "      <td>-1.753192</td>\n",
       "      <td>...</td>\n",
       "      <td>1.243817</td>\n",
       "      <td>1.685532</td>\n",
       "      <td>-0.577811</td>\n",
       "      <td>1.307564</td>\n",
       "      <td>1.536135</td>\n",
       "      <td>1.131523</td>\n",
       "      <td>-1.121663</td>\n",
       "      <td>-0.449363</td>\n",
       "      <td>-0.188203</td>\n",
       "      <td>0.380718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.097101</td>\n",
       "      <td>1.781492</td>\n",
       "      <td>-1.007008</td>\n",
       "      <td>0.476383</td>\n",
       "      <td>-0.860520</td>\n",
       "      <td>0.237922</td>\n",
       "      <td>0.011948</td>\n",
       "      <td>0.391437</td>\n",
       "      <td>-2.201391</td>\n",
       "      <td>-1.233196</td>\n",
       "      <td>...</td>\n",
       "      <td>1.523362</td>\n",
       "      <td>0.373167</td>\n",
       "      <td>-0.474670</td>\n",
       "      <td>0.626380</td>\n",
       "      <td>0.780064</td>\n",
       "      <td>0.940919</td>\n",
       "      <td>0.946058</td>\n",
       "      <td>-0.160582</td>\n",
       "      <td>-0.514086</td>\n",
       "      <td>0.045350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.219244</td>\n",
       "      <td>2.916082</td>\n",
       "      <td>-1.762921</td>\n",
       "      <td>0.105094</td>\n",
       "      <td>0.824574</td>\n",
       "      <td>-0.478362</td>\n",
       "      <td>-1.952845</td>\n",
       "      <td>1.312541</td>\n",
       "      <td>-0.923542</td>\n",
       "      <td>0.801927</td>\n",
       "      <td>...</td>\n",
       "      <td>0.551180</td>\n",
       "      <td>-1.120841</td>\n",
       "      <td>1.259951</td>\n",
       "      <td>1.457078</td>\n",
       "      <td>-0.028447</td>\n",
       "      <td>-0.426747</td>\n",
       "      <td>-0.214212</td>\n",
       "      <td>-0.500549</td>\n",
       "      <td>-0.962585</td>\n",
       "      <td>0.129345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.018039</td>\n",
       "      <td>0.863435</td>\n",
       "      <td>-1.183302</td>\n",
       "      <td>1.088019</td>\n",
       "      <td>-1.939883</td>\n",
       "      <td>0.270709</td>\n",
       "      <td>0.823084</td>\n",
       "      <td>-2.697592</td>\n",
       "      <td>-1.766388</td>\n",
       "      <td>-0.732310</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023433</td>\n",
       "      <td>1.979430</td>\n",
       "      <td>-1.010571</td>\n",
       "      <td>-0.306624</td>\n",
       "      <td>0.225777</td>\n",
       "      <td>1.095818</td>\n",
       "      <td>0.084233</td>\n",
       "      <td>-0.324941</td>\n",
       "      <td>-0.603342</td>\n",
       "      <td>-0.830068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.536368</td>\n",
       "      <td>0.197603</td>\n",
       "      <td>-1.544138</td>\n",
       "      <td>-1.689236</td>\n",
       "      <td>0.284575</td>\n",
       "      <td>0.396129</td>\n",
       "      <td>1.276209</td>\n",
       "      <td>0.722421</td>\n",
       "      <td>-2.394707</td>\n",
       "      <td>0.321576</td>\n",
       "      <td>...</td>\n",
       "      <td>0.350161</td>\n",
       "      <td>1.942544</td>\n",
       "      <td>-1.101885</td>\n",
       "      <td>1.349296</td>\n",
       "      <td>-0.199763</td>\n",
       "      <td>0.944104</td>\n",
       "      <td>-0.153682</td>\n",
       "      <td>-0.258374</td>\n",
       "      <td>0.311952</td>\n",
       "      <td>-1.736649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119995</th>\n",
       "      <td>6.933061</td>\n",
       "      <td>0.223553</td>\n",
       "      <td>0.581143</td>\n",
       "      <td>-2.387336</td>\n",
       "      <td>1.327399</td>\n",
       "      <td>0.092358</td>\n",
       "      <td>-1.086349</td>\n",
       "      <td>-2.972760</td>\n",
       "      <td>-2.036876</td>\n",
       "      <td>1.611542</td>\n",
       "      <td>...</td>\n",
       "      <td>0.344639</td>\n",
       "      <td>3.493837</td>\n",
       "      <td>-1.521361</td>\n",
       "      <td>1.758011</td>\n",
       "      <td>-2.685496</td>\n",
       "      <td>2.848763</td>\n",
       "      <td>1.328479</td>\n",
       "      <td>0.294635</td>\n",
       "      <td>-0.581983</td>\n",
       "      <td>1.621503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119996</th>\n",
       "      <td>4.288282</td>\n",
       "      <td>-1.342496</td>\n",
       "      <td>-0.756865</td>\n",
       "      <td>-3.048436</td>\n",
       "      <td>-0.557106</td>\n",
       "      <td>0.130120</td>\n",
       "      <td>0.525284</td>\n",
       "      <td>0.545878</td>\n",
       "      <td>-1.002240</td>\n",
       "      <td>0.912907</td>\n",
       "      <td>...</td>\n",
       "      <td>2.103725</td>\n",
       "      <td>-0.307448</td>\n",
       "      <td>0.220690</td>\n",
       "      <td>0.857474</td>\n",
       "      <td>-0.232843</td>\n",
       "      <td>0.518466</td>\n",
       "      <td>1.228551</td>\n",
       "      <td>0.531755</td>\n",
       "      <td>0.380048</td>\n",
       "      <td>1.562379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119997</th>\n",
       "      <td>0.540718</td>\n",
       "      <td>-1.093760</td>\n",
       "      <td>-1.308527</td>\n",
       "      <td>-1.786093</td>\n",
       "      <td>-0.897580</td>\n",
       "      <td>-2.366068</td>\n",
       "      <td>1.439508</td>\n",
       "      <td>0.350657</td>\n",
       "      <td>-1.043596</td>\n",
       "      <td>-0.301704</td>\n",
       "      <td>...</td>\n",
       "      <td>1.418113</td>\n",
       "      <td>-0.984991</td>\n",
       "      <td>1.137200</td>\n",
       "      <td>0.194888</td>\n",
       "      <td>0.645412</td>\n",
       "      <td>0.118288</td>\n",
       "      <td>2.641707</td>\n",
       "      <td>0.129081</td>\n",
       "      <td>0.496854</td>\n",
       "      <td>-0.659888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119998</th>\n",
       "      <td>3.679487</td>\n",
       "      <td>0.156296</td>\n",
       "      <td>-1.274762</td>\n",
       "      <td>-1.117082</td>\n",
       "      <td>1.307523</td>\n",
       "      <td>-1.713429</td>\n",
       "      <td>0.888465</td>\n",
       "      <td>0.114700</td>\n",
       "      <td>1.253176</td>\n",
       "      <td>-1.457275</td>\n",
       "      <td>...</td>\n",
       "      <td>1.261752</td>\n",
       "      <td>0.012643</td>\n",
       "      <td>-0.542243</td>\n",
       "      <td>-1.032002</td>\n",
       "      <td>0.572352</td>\n",
       "      <td>0.123144</td>\n",
       "      <td>-0.120796</td>\n",
       "      <td>-0.471654</td>\n",
       "      <td>-0.564854</td>\n",
       "      <td>1.195555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119999</th>\n",
       "      <td>2.888836</td>\n",
       "      <td>0.663419</td>\n",
       "      <td>-1.031527</td>\n",
       "      <td>-0.420753</td>\n",
       "      <td>-1.882425</td>\n",
       "      <td>-1.266466</td>\n",
       "      <td>1.102389</td>\n",
       "      <td>-0.432328</td>\n",
       "      <td>-0.976589</td>\n",
       "      <td>-0.397505</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.552401</td>\n",
       "      <td>0.453831</td>\n",
       "      <td>-2.514176</td>\n",
       "      <td>1.052223</td>\n",
       "      <td>-1.205719</td>\n",
       "      <td>1.118087</td>\n",
       "      <td>1.599995</td>\n",
       "      <td>-1.045302</td>\n",
       "      <td>2.003965</td>\n",
       "      <td>-0.460954</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120000 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1         2         5         6         7         11  \\\n",
       "0       1.791994  3.303306 -0.246607  1.033834  1.051862 -0.822095 -1.564288   \n",
       "1       0.097101  1.781492 -1.007008  0.476383 -0.860520  0.237922  0.011948   \n",
       "2       6.219244  2.916082 -1.762921  0.105094  0.824574 -0.478362 -1.952845   \n",
       "3       2.018039  0.863435 -1.183302  1.088019 -1.939883  0.270709  0.823084   \n",
       "4       0.536368  0.197603 -1.544138 -1.689236  0.284575  0.396129  1.276209   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "119995  6.933061  0.223553  0.581143 -2.387336  1.327399  0.092358 -1.086349   \n",
       "119996  4.288282 -1.342496 -0.756865 -3.048436 -0.557106  0.130120  0.525284   \n",
       "119997  0.540718 -1.093760 -1.308527 -1.786093 -0.897580 -2.366068  1.439508   \n",
       "119998  3.679487  0.156296 -1.274762 -1.117082  1.307523 -1.713429  0.888465   \n",
       "119999  2.888836  0.663419 -1.031527 -0.420753 -1.882425 -1.266466  1.102389   \n",
       "\n",
       "              12        14        16  ...        24        25        27  \\\n",
       "0       3.893851 -1.970771 -1.753192  ...  1.243817  1.685532 -0.577811   \n",
       "1       0.391437 -2.201391 -1.233196  ...  1.523362  0.373167 -0.474670   \n",
       "2       1.312541 -0.923542  0.801927  ...  0.551180 -1.120841  1.259951   \n",
       "3      -2.697592 -1.766388 -0.732310  ...  0.023433  1.979430 -1.010571   \n",
       "4       0.722421 -2.394707  0.321576  ...  0.350161  1.942544 -1.101885   \n",
       "...          ...       ...       ...  ...       ...       ...       ...   \n",
       "119995 -2.972760 -2.036876  1.611542  ...  0.344639  3.493837 -1.521361   \n",
       "119996  0.545878 -1.002240  0.912907  ...  2.103725 -0.307448  0.220690   \n",
       "119997  0.350657 -1.043596 -0.301704  ...  1.418113 -0.984991  1.137200   \n",
       "119998  0.114700  1.253176 -1.457275  ...  1.261752  0.012643 -0.542243   \n",
       "119999 -0.432328 -0.976589 -0.397505  ... -0.552401  0.453831 -2.514176   \n",
       "\n",
       "              45        52        55        60        71        73        75  \n",
       "0       1.307564  1.536135  1.131523 -1.121663 -0.449363 -0.188203  0.380718  \n",
       "1       0.626380  0.780064  0.940919  0.946058 -0.160582 -0.514086  0.045350  \n",
       "2       1.457078 -0.028447 -0.426747 -0.214212 -0.500549 -0.962585  0.129345  \n",
       "3      -0.306624  0.225777  1.095818  0.084233 -0.324941 -0.603342 -0.830068  \n",
       "4       1.349296 -0.199763  0.944104 -0.153682 -0.258374  0.311952 -1.736649  \n",
       "...          ...       ...       ...       ...       ...       ...       ...  \n",
       "119995  1.758011 -2.685496  2.848763  1.328479  0.294635 -0.581983  1.621503  \n",
       "119996  0.857474 -0.232843  0.518466  1.228551  0.531755  0.380048  1.562379  \n",
       "119997  0.194888  0.645412  0.118288  2.641707  0.129081  0.496854 -0.659888  \n",
       "119998 -1.032002  0.572352  0.123144 -0.120796 -0.471654 -0.564854  1.195555  \n",
       "119999  1.052223 -1.205719  1.118087  1.599995 -1.045302  2.003965 -0.460954  \n",
       "\n",
       "[120000 rows x 25 columns]"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sf = features_pca.loc[:, rows_above_threshold]\n",
    "\n",
    "sf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05XkZMeQCita",
   "metadata": {
    "id": "05XkZMeQCita"
   },
   "source": [
    "<h3 style=\"color:rgb(0,120,170)\">3. Cross-Validation: Stratified K-Fold </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "F4CPHevTPRBO",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 396
    },
    "id": "F4CPHevTPRBO",
    "outputId": "c0667e40-32c9-4aec-e59c-84ffa9205db8"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a14d78",
   "metadata": {},
   "source": [
    "<h3 style=\"color:rgb(0,120,170)\">4. Models </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "X9fitBITE2wO",
   "metadata": {
    "id": "X9fitBITE2wO"
   },
   "source": [
    "<h3 style=\"color:rgb(0,120,170)\">Method 1: Random Forest</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "kccVRKENErGr",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kccVRKENErGr",
    "outputId": "bb5c9e0a-18f7-450b-85d2-fadeab76ed2c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 71.15%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Split the data into a training set and a test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(sf, labels.iloc[:, 0], test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a Random Forest model on the training set\n",
    "rfc = RandomForestClassifier()\n",
    "rfc.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "y_pred = rfc.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy on test set: {:.2f}%\".format(accuracy * 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "593f0801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.71      0.99      0.83     17056\n",
      "         1.0       0.07      0.00      0.00      1148\n",
      "         2.0       0.60      0.04      0.07      1881\n",
      "         3.0       0.45      0.02      0.04      1578\n",
      "         4.0       0.00      0.00      0.00       470\n",
      "         5.0       0.85      0.02      0.05       979\n",
      "         6.0       0.00      0.00      0.00       888\n",
      "\n",
      "    accuracy                           0.71     24000\n",
      "   macro avg       0.38      0.15      0.14     24000\n",
      "weighted avg       0.62      0.71      0.60     24000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Generate predictions on the test set\n",
    "y_pred = rfc.predict(X_test)\n",
    "\n",
    "# Generate the classification report\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "f1fcc7b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: 64.74%\n",
      "Fold 2: 70.55%\n",
      "Fold 3: 69.66%\n",
      "Fold 4: 68.95%\n",
      "Fold 5: 43.98%\n",
      "Average Accuracy: 63.58%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "scores = cross_val_score(rfc, sf, labels.iloc[:, 0], cv=5)\n",
    "\n",
    "# Print the accuracy scores for each fold\n",
    "for fold, score in enumerate(scores):\n",
    "    print(\"Fold {}: {:.2f}%\".format(fold+1, score * 100))\n",
    "\n",
    "# Calculate and print the average accuracy\n",
    "average_accuracy = scores.mean()\n",
    "print(\"Average Accuracy: {:.2f}%\".format(average_accuracy * 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "1065ad01",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.71      0.99      0.83     17056\n",
      "         1.0       0.22      0.00      0.01      1148\n",
      "         2.0       0.61      0.04      0.07      1881\n",
      "         3.0       0.42      0.02      0.04      1578\n",
      "         4.0       0.00      0.00      0.00       470\n",
      "         5.0       0.82      0.02      0.05       979\n",
      "         6.0       0.00      0.00      0.00       888\n",
      "\n",
      "    accuracy                           0.71     24000\n",
      "   macro avg       0.40      0.15      0.14     24000\n",
      "weighted avg       0.63      0.71      0.60     24000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.71      0.99      0.83     17056\n",
      "         1.0       0.00      0.00      0.00      1148\n",
      "         2.0       0.59      0.03      0.06      1881\n",
      "         3.0       0.40      0.02      0.04      1578\n",
      "         4.0       0.00      0.00      0.00       470\n",
      "         5.0       0.79      0.02      0.04       979\n",
      "         6.0       0.00      0.00      0.00       888\n",
      "\n",
      "    accuracy                           0.71     24000\n",
      "   macro avg       0.36      0.15      0.14     24000\n",
      "weighted avg       0.61      0.71      0.60     24000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.71      0.99      0.83     17056\n",
      "         1.0       0.21      0.00      0.01      1148\n",
      "         2.0       0.60      0.03      0.06      1881\n",
      "         3.0       0.46      0.02      0.04      1578\n",
      "         4.0       0.00      0.00      0.00       470\n",
      "         5.0       0.81      0.02      0.04       979\n",
      "         6.0       0.00      0.00      0.00       888\n",
      "\n",
      "    accuracy                           0.71     24000\n",
      "   macro avg       0.40      0.15      0.14     24000\n",
      "weighted avg       0.63      0.71      0.60     24000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.71      0.99      0.83     17056\n",
      "         1.0       0.11      0.00      0.00      1148\n",
      "         2.0       0.58      0.04      0.07      1881\n",
      "         3.0       0.43      0.02      0.04      1578\n",
      "         4.0       0.00      0.00      0.00       470\n",
      "         5.0       0.83      0.02      0.04       979\n",
      "         6.0       0.00      0.00      0.00       888\n",
      "\n",
      "    accuracy                           0.71     24000\n",
      "   macro avg       0.38      0.15      0.14     24000\n",
      "weighted avg       0.62      0.71      0.60     24000\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.71      0.99      0.83     17056\n",
      "         1.0       0.26      0.00      0.01      1148\n",
      "         2.0       0.58      0.04      0.07      1881\n",
      "         3.0       0.42      0.02      0.04      1578\n",
      "         4.0       0.00      0.00      0.00       470\n",
      "         5.0       0.87      0.03      0.05       979\n",
      "         6.0       1.00      0.00      0.00       888\n",
      "\n",
      "    accuracy                           0.71     24000\n",
      "   macro avg       0.55      0.15      0.14     24000\n",
      "weighted avg       0.66      0.71      0.60     24000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "for fold, (train_index, test_index) in enumerate(skf.split(X_train, y_train)):\n",
    "    X_train_fold, X_val_fold = X_train.iloc[train_index], X_train.iloc[val_index]\n",
    "    y_train_fold, y_val_fold = y_train.iloc[train_index], y_train.iloc[val_index]\n",
    "    \n",
    "    rfc = RandomForestClassifier()\n",
    "    rfc.fit(X_train, y_train.values.ravel())\n",
    "    \n",
    "    y_pred = rfc.predict(X_test)\n",
    "    \n",
    "    report = classification_report(y_test, y_pred)\n",
    "    \n",
    "    print(\"Classification Report:\")\n",
    "    print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e85cc6",
   "metadata": {
    "id": "a8e85cc6"
   },
   "source": [
    "<h3 style=\"color:rgb(0,120,170)\">Method 2: Naive Bayes</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "P38lnN3CoL7r",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 851
    },
    "id": "P38lnN3CoL7r",
    "outputId": "336b3cbd-58fe-4914-a39f-36e6e2fad765"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.69      0.54      0.61     17056\n",
      "         1.0       0.18      0.33      0.24      1148\n",
      "         2.0       0.37      0.14      0.20      1881\n",
      "         3.0       0.28      0.08      0.13      1578\n",
      "         4.0       0.04      0.62      0.08       470\n",
      "         5.0       0.13      0.08      0.10       979\n",
      "         6.0       0.26      0.04      0.07       888\n",
      "\n",
      "    accuracy                           0.43     24000\n",
      "   macro avg       0.28      0.26      0.20     24000\n",
      "weighted avg       0.56      0.43      0.47     24000\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.69      0.54      0.61     17056\n",
      "         1.0       0.18      0.33      0.24      1148\n",
      "         2.0       0.37      0.14      0.20      1881\n",
      "         3.0       0.28      0.08      0.13      1578\n",
      "         4.0       0.04      0.62      0.08       470\n",
      "         5.0       0.13      0.08      0.10       979\n",
      "         6.0       0.26      0.04      0.07       888\n",
      "\n",
      "    accuracy                           0.43     24000\n",
      "   macro avg       0.28      0.26      0.20     24000\n",
      "weighted avg       0.56      0.43      0.47     24000\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.69      0.54      0.61     17056\n",
      "         1.0       0.18      0.33      0.24      1148\n",
      "         2.0       0.37      0.14      0.20      1881\n",
      "         3.0       0.28      0.08      0.13      1578\n",
      "         4.0       0.04      0.62      0.08       470\n",
      "         5.0       0.13      0.08      0.10       979\n",
      "         6.0       0.26      0.04      0.07       888\n",
      "\n",
      "    accuracy                           0.43     24000\n",
      "   macro avg       0.28      0.26      0.20     24000\n",
      "weighted avg       0.56      0.43      0.47     24000\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.69      0.54      0.61     17056\n",
      "         1.0       0.18      0.33      0.24      1148\n",
      "         2.0       0.37      0.14      0.20      1881\n",
      "         3.0       0.28      0.08      0.13      1578\n",
      "         4.0       0.04      0.62      0.08       470\n",
      "         5.0       0.13      0.08      0.10       979\n",
      "         6.0       0.26      0.04      0.07       888\n",
      "\n",
      "    accuracy                           0.43     24000\n",
      "   macro avg       0.28      0.26      0.20     24000\n",
      "weighted avg       0.56      0.43      0.47     24000\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.69      0.54      0.61     17056\n",
      "         1.0       0.18      0.33      0.24      1148\n",
      "         2.0       0.37      0.14      0.20      1881\n",
      "         3.0       0.28      0.08      0.13      1578\n",
      "         4.0       0.04      0.62      0.08       470\n",
      "         5.0       0.13      0.08      0.10       979\n",
      "         6.0       0.26      0.04      0.07       888\n",
      "\n",
      "    accuracy                           0.43     24000\n",
      "   macro avg       0.28      0.26      0.20     24000\n",
      "weighted avg       0.56      0.43      0.47     24000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for fold, (train_index, test_index) in enumerate(skf.split(X_train, y_train)):\n",
    "    X_train_fold, X_val_fold = X_train.iloc[train_index], X_train.iloc[val_index]\n",
    "    y_train_fold, y_val_fold = y_train.iloc[train_index], y_train.iloc[val_index]\n",
    "    \n",
    "    gnb = GaussianNB()\n",
    "    gnb.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = gnb.predict(X_test)\n",
    "    \n",
    "    report = classification_report(y_test, y_pred)\n",
    "    \n",
    "    print(\"Classification Report:\")\n",
    "    print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "57c7c6ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "confusion_mat = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "sns.heatmap(confusion_mat.astype(int), annot=True, cmap='Blues', fmt='d')\n",
    "\n",
    "# Add labels, title, and axis ticks\n",
    "plt.xlabel('Predicted labels')\n",
    "plt.ylabel('True labels')\n",
    "plt.title('Confusion Matrix')\n",
    "\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b119ddfd",
   "metadata": {
    "id": "b119ddfd"
   },
   "source": [
    "<h3 style=\"color:rgb(0,120,170)\">Method 3: Quadratic Discriminant Analysis (QDA)</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "xPPeDrAxWTZc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xPPeDrAxWTZc",
    "outputId": "474fc32e-c6d8-4f9c-a1b0-8c860243b91d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 24.38%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "# Split the data into a training set and a test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(sf, labels.iloc[:, 0], test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a QDA model on the training set\n",
    "qda = QuadraticDiscriminantAnalysis()\n",
    "qda.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "y_pred = qda.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy on test set: {:.2f}%\".format(accuracy * 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "343a294f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.09      0.16     17056\n",
      "         1.0       0.26      0.75      0.39      1148\n",
      "         2.0       0.23      0.61      0.33      1881\n",
      "         3.0       0.28      0.34      0.31      1578\n",
      "         4.0       0.05      0.73      0.09       470\n",
      "         5.0       0.18      0.45      0.26       979\n",
      "         6.0       0.17      0.37      0.23       888\n",
      "\n",
      "    accuracy                           0.22     24000\n",
      "   macro avg       0.27      0.48      0.25     24000\n",
      "weighted avg       0.58      0.22      0.20     24000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Generate predictions on the test set\n",
    "y_pred = qda.predict(X_test)\n",
    "\n",
    "# Generate the classification report\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "c0aeb691",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: 18.02%\n",
      "Fold 2: 16.92%\n",
      "Fold 3: 18.53%\n",
      "Fold 4: 21.03%\n",
      "Fold 5: 17.67%\n",
      "Average Accuracy: 18.44%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "scores = cross_val_score(qda, sf, labels.iloc[:, 0], cv=5)\n",
    "\n",
    "# Print the accuracy scores for each fold\n",
    "for fold, score in enumerate(scores):\n",
    "    print(\"Fold {}: {:.2f}%\".format(fold+1, score * 100))\n",
    "\n",
    "# Calculate and print the average accuracy\n",
    "average_accuracy = scores.mean()\n",
    "print(\"Average Accuracy: {:.2f}%\".format(average_accuracy * 100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "980133bc",
   "metadata": {},
   "source": [
    "<h3 style=\"color:rgb(0,120,170)\">Method 4: KNN</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "9a049a91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.73      0.90      0.80     17056\n",
      "         1.0       0.28      0.17      0.21      1148\n",
      "         2.0       0.41      0.19      0.26      1881\n",
      "         3.0       0.30      0.12      0.17      1578\n",
      "         4.0       0.10      0.02      0.03       470\n",
      "         5.0       0.39      0.14      0.21       979\n",
      "         6.0       0.24      0.08      0.12       888\n",
      "\n",
      "    accuracy                           0.68     24000\n",
      "   macro avg       0.35      0.23      0.26     24000\n",
      "weighted avg       0.61      0.68      0.63     24000\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.73      0.90      0.80     17056\n",
      "         1.0       0.28      0.17      0.21      1148\n",
      "         2.0       0.41      0.19      0.26      1881\n",
      "         3.0       0.30      0.12      0.17      1578\n",
      "         4.0       0.10      0.02      0.03       470\n",
      "         5.0       0.39      0.14      0.21       979\n",
      "         6.0       0.24      0.08      0.12       888\n",
      "\n",
      "    accuracy                           0.68     24000\n",
      "   macro avg       0.35      0.23      0.26     24000\n",
      "weighted avg       0.61      0.68      0.63     24000\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.73      0.90      0.80     17056\n",
      "         1.0       0.28      0.17      0.21      1148\n",
      "         2.0       0.41      0.19      0.26      1881\n",
      "         3.0       0.30      0.12      0.17      1578\n",
      "         4.0       0.10      0.02      0.03       470\n",
      "         5.0       0.39      0.14      0.21       979\n",
      "         6.0       0.24      0.08      0.12       888\n",
      "\n",
      "    accuracy                           0.68     24000\n",
      "   macro avg       0.35      0.23      0.26     24000\n",
      "weighted avg       0.61      0.68      0.63     24000\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.73      0.90      0.80     17056\n",
      "         1.0       0.28      0.17      0.21      1148\n",
      "         2.0       0.41      0.19      0.26      1881\n",
      "         3.0       0.30      0.12      0.17      1578\n",
      "         4.0       0.10      0.02      0.03       470\n",
      "         5.0       0.39      0.14      0.21       979\n",
      "         6.0       0.24      0.08      0.12       888\n",
      "\n",
      "    accuracy                           0.68     24000\n",
      "   macro avg       0.35      0.23      0.26     24000\n",
      "weighted avg       0.61      0.68      0.63     24000\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.73      0.90      0.80     17056\n",
      "         1.0       0.28      0.17      0.21      1148\n",
      "         2.0       0.41      0.19      0.26      1881\n",
      "         3.0       0.30      0.12      0.17      1578\n",
      "         4.0       0.10      0.02      0.03       470\n",
      "         5.0       0.39      0.14      0.21       979\n",
      "         6.0       0.24      0.08      0.12       888\n",
      "\n",
      "    accuracy                           0.68     24000\n",
      "   macro avg       0.35      0.23      0.26     24000\n",
      "weighted avg       0.61      0.68      0.63     24000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for fold, (train_index, test_index) in enumerate(skf.split(X_train, y_train)):\n",
    "    X_train_fold, X_val_fold = X_train.iloc[train_index], X_train.iloc[val_index]\n",
    "    y_train_fold, y_val_fold = y_train.iloc[train_index], y_train.iloc[val_index]\n",
    "    \n",
    "    knn = KNeighborsClassifier(n_neighbors=3)\n",
    "    knn.fit(X_train, y_train.values.ravel())\n",
    "    \n",
    "    y_pred = knn.predict(X_test)\n",
    "    \n",
    "    report = classification_report(y_test, y_pred)\n",
    "    \n",
    "    print(\"Classification Report:\")\n",
    "    print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55cf9ef7",
   "metadata": {},
   "source": [
    "<h3 style=\"color:rgb(0,120,170)\">Method 5: Decision Tree Classifier</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "a56f69a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.70      0.71     17056\n",
      "         1.0       0.18      0.20      0.19      1148\n",
      "         2.0       0.17      0.17      0.17      1881\n",
      "         3.0       0.14      0.16      0.15      1578\n",
      "         4.0       0.05      0.06      0.05       470\n",
      "         5.0       0.12      0.13      0.12       979\n",
      "         6.0       0.11      0.12      0.12       888\n",
      "\n",
      "    accuracy                           0.54     24000\n",
      "   macro avg       0.21      0.22      0.22     24000\n",
      "weighted avg       0.55      0.54      0.55     24000\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.70      0.71     17056\n",
      "         1.0       0.19      0.20      0.19      1148\n",
      "         2.0       0.17      0.17      0.17      1881\n",
      "         3.0       0.14      0.16      0.15      1578\n",
      "         4.0       0.05      0.06      0.05       470\n",
      "         5.0       0.11      0.12      0.12       979\n",
      "         6.0       0.11      0.12      0.11       888\n",
      "\n",
      "    accuracy                           0.54     24000\n",
      "   macro avg       0.21      0.22      0.22     24000\n",
      "weighted avg       0.55      0.54      0.55     24000\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.70      0.71     17056\n",
      "         1.0       0.17      0.20      0.18      1148\n",
      "         2.0       0.18      0.17      0.18      1881\n",
      "         3.0       0.14      0.16      0.15      1578\n",
      "         4.0       0.05      0.06      0.06       470\n",
      "         5.0       0.12      0.13      0.13       979\n",
      "         6.0       0.11      0.12      0.12       888\n",
      "\n",
      "    accuracy                           0.54     24000\n",
      "   macro avg       0.22      0.22      0.22     24000\n",
      "weighted avg       0.55      0.54      0.55     24000\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.70      0.71     17056\n",
      "         1.0       0.18      0.19      0.18      1148\n",
      "         2.0       0.18      0.17      0.17      1881\n",
      "         3.0       0.14      0.16      0.15      1578\n",
      "         4.0       0.06      0.07      0.07       470\n",
      "         5.0       0.12      0.13      0.13       979\n",
      "         6.0       0.11      0.11      0.11       888\n",
      "\n",
      "    accuracy                           0.54     24000\n",
      "   macro avg       0.22      0.22      0.22     24000\n",
      "weighted avg       0.55      0.54      0.55     24000\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.70      0.71     17056\n",
      "         1.0       0.18      0.20      0.19      1148\n",
      "         2.0       0.18      0.18      0.18      1881\n",
      "         3.0       0.15      0.16      0.15      1578\n",
      "         4.0       0.05      0.06      0.05       470\n",
      "         5.0       0.11      0.12      0.11       979\n",
      "         6.0       0.12      0.13      0.13       888\n",
      "\n",
      "    accuracy                           0.54     24000\n",
      "   macro avg       0.22      0.22      0.22     24000\n",
      "weighted avg       0.56      0.54      0.55     24000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for fold, (train_index, test_index) in enumerate(skf.split(X_train, y_train)):\n",
    "    X_train_fold, X_val_fold = X_train.iloc[train_index], X_train.iloc[val_index]\n",
    "    y_train_fold, y_val_fold = y_train.iloc[train_index], y_train.iloc[val_index]\n",
    "    \n",
    "    dtc = DecisionTreeClassifier()\n",
    "    dtc.fit(X_train, y_train.values.ravel())\n",
    "    \n",
    "    y_pred = dtc.predict(X_test)\n",
    "    \n",
    "    report = classification_report(y_test, y_pred)\n",
    "    \n",
    "    print(\"Classification Report:\")\n",
    "    print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885c838a",
   "metadata": {},
   "source": [
    "<h3 style=\"color:rgb(0,120,170)\">Variations of Random Forest</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "74f9e9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Splitting the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(sf, labels.iloc[:, 0], test_size=0.2, random_state=42)\n",
    "\n",
    "# Further splitting the training data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, stratify=y_train, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "43a5cef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy: 71.26%\n",
      "Standard Deviation: 0.09%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Creating a Random Forest classifier\n",
    "rf_classifier = RandomForestClassifier()\n",
    "\n",
    "# Performing cross-validation on the training set\n",
    "cv_scores = cross_val_score(rf_classifier, X_train, y_train, cv=5)  # cv=5 specifies 5-fold cross-validation\n",
    "\n",
    "# Average accuracy and standard deviation across folds\n",
    "avg_accuracy = cv_scores.mean()\n",
    "std_dev = cv_scores.std()\n",
    "\n",
    "# Printing the results\n",
    "print(\"Average Accuracy: {:.2f}%\".format(avg_accuracy * 100))\n",
    "print(\"Standard Deviation: {:.2f}%\".format(std_dev * 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "b942baaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 71.23%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Creating a Random Forest classifier\n",
    "rf_classifier = RandomForestClassifier()\n",
    "\n",
    "# Training the classifier\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Making predictions on the validation set\n",
    "y_val_pred = rf_classifier.predict(X_val)\n",
    "\n",
    "# Calculating accuracy on the validation set\n",
    "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "\n",
    "# Making predictions on the test set\n",
    "y_test_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "# Calculating accuracy on the test set\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "# Printing the results\n",
    "print(\"Validation Accuracy: {:.2f}%\".format(val_accuracy * 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "836e3aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "for train_index, val_index in skf.split(X_train, y_train):\n",
    "    X_train_fold, X_val_fold = X_train.iloc[train_index], X_train.iloc[val_index]\n",
    "    y_train_fold, y_val_fold = y_train.iloc[train_index], y_train.iloc[val_index]\n",
    "    # Train and evaluate your model on each fold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "de05935c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Create a Random Forest classifier\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the classifier\n",
    "rf_classifier.fit(X_train_fold, y_train_fold)\n",
    "\n",
    "# Evaluate the classifier on the validation fold\n",
    "accuracy = rf_classifier.score(X_val_fold, y_val_fold)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "79e730b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7115"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "53f073c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance Metrics:\n",
      "Average Accuracy: 0.7134\n",
      "Average Precision: [0.71449755 0.27665446 0.59724666 0.54691515 0.         0.82527806\n",
      " 0.        ]\n",
      "Average Recall: [0.99474393 0.00213447 0.0400106  0.02069486 0.         0.02759061\n",
      " 0.        ]\n",
      "Average F1 Score: [0.8316462  0.00423149 0.07498089 0.03987179 0.         0.0533486\n",
      " 0.        ]\n",
      "Confusion Matrix (Last Fold):\n",
      "[[13587    12    37    20     0     5     0]\n",
      " [  936     1     0     0     0     0     0]\n",
      " [ 1362     0    52     0     0     0     0]\n",
      " [ 1294     0     1    29     0     0     0]\n",
      " [  371     0     0     0     0     0     0]\n",
      " [  802     0     0     0     0    25     0]\n",
      " [  666     0     0     0     0     0     0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "# Create a Random Forest classifier\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Perform stratified k-fold cross-validation\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "accuracies = []\n",
    "precisions = []\n",
    "recalls = []\n",
    "f1_scores = []\n",
    "confusion_matrices = []\n",
    "\n",
    "for train_index, val_index in skf.split(X_train, y_train):\n",
    "    X_train_fold, X_val_fold = X_train.iloc[train_index], X_train.iloc[val_index]\n",
    "    y_train_fold, y_val_fold = y_train.iloc[train_index], y_train.iloc[val_index]\n",
    "    \n",
    "    # Train the classifier\n",
    "    rf_classifier.fit(X_train_fold, y_train_fold)\n",
    "    \n",
    "    # Predict the labels for the validation fold\n",
    "    y_pred_fold = rf_classifier.predict(X_val_fold)\n",
    "    \n",
    "    # Compute evaluation metrics\n",
    "    accuracy = accuracy_score(y_val_fold, y_pred_fold)\n",
    "    precision = precision_score(y_val_fold, y_pred_fold, average=None)\n",
    "    recall = recall_score(y_val_fold, y_pred_fold, average=None)\n",
    "    f1 = f1_score(y_val_fold, y_pred_fold, average=None)\n",
    "    confusion_matrix_fold = confusion_matrix(y_val_fold, y_pred_fold)\n",
    "    \n",
    "    accuracies.append(accuracy)\n",
    "    precisions.append(precision)\n",
    "    recalls.append(recall)\n",
    "    f1_scores.append(f1)\n",
    "    confusion_matrices.append(confusion_matrix_fold)\n",
    "\n",
    "# Compute average metrics across all folds\n",
    "avg_accuracy = sum(accuracies) / len(accuracies)\n",
    "avg_precision = sum(precisions) / len(precisions)\n",
    "avg_recall = sum(recalls) / len(recalls)\n",
    "avg_f1 = sum(f1_scores) / len(f1_scores)\n",
    "\n",
    "print(\"Performance Metrics:\")\n",
    "print(f\"Average Accuracy: {avg_accuracy:.4f}\")\n",
    "print(f\"Average Precision: {avg_precision}\")\n",
    "print(f\"Average Recall: {avg_recall}\")\n",
    "print(f\"Average F1 Score: {avg_f1}\")\n",
    "\n",
    "# Confusion matrix for the last fold\n",
    "last_fold_confusion_matrix = confusion_matrices[-1]\n",
    "print(\"Confusion Matrix (Last Fold):\")\n",
    "print(last_fold_confusion_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0215ff9",
   "metadata": {},
   "source": [
    "<h3 style=\"color:rgb(0,120,170)\">Inefficient Methods of Dimensionality Reduction</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "214a63f7",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/72/k144hg1s1bl5jf6b4jqxr8zw0000gn/T/ipykernel_31881/1172648184.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Fit selector to the PCA-transformed data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# Get the ranking of each feature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/feature_selection/_rfe.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    182\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m         \"\"\"\n\u001b[0;32m--> 184\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/feature_selection/_rfe.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, step_score)\u001b[0m\n\u001b[1;32m    239\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Fitting estimator with %d features.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msupport_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m             \u001b[0;31m# Get importance and rank them\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    385\u001b[0m             \u001b[0;31m# parallel_backend contexts set at a higher level,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m             \u001b[0;31m# since correctness does not rely on using threads.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m             trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n\u001b[0m\u001b[1;32m    388\u001b[0m                              \u001b[0;34m**\u001b[0m\u001b[0m_joblib_parallel_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'threads'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m                 delayed(_parallel_build_trees)(\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1044\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1045\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1046\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1047\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1048\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    859\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    860\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 861\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    862\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    863\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    777\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[1;32m    167\u001b[0m                                                         indices=indices)\n\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    901\u001b[0m         \"\"\"\n\u001b[1;32m    902\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 903\u001b[0;31m         super().fit(\n\u001b[0m\u001b[1;32m    904\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    905\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    392\u001b[0m                                            min_impurity_split)\n\u001b[1;32m    393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Initialize the estimator\n",
    "estimator = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Initialize RFE with 1 feature to eliminate at each step\n",
    "selector = RFE(estimator, n_features_to_select=50, step=1)\n",
    "\n",
    "# Fit selector to the PCA-transformed data\n",
    "selector.fit(features, labels)\n",
    "\n",
    "# Get the ranking of each feature\n",
    "ranking = selector.ranking_\n",
    "\n",
    "# Sort the features based on their ranking\n",
    "sorted_features = sorted(zip(features.columns, ranking), key=lambda x: x[1])\n",
    "\n",
    "# Select the top-k important features\n",
    "k = 50  # Choose the desired number of features to keep\n",
    "selected_features = [feat for feat, rank in sorted_features[:k]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "acf6d905",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:518: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 299.2491455078125, tolerance: 231.80441284179688\n",
      "  model = cd_fast.enet_coordinate_descent_multi_task(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:518: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 358.0291442871094, tolerance: 231.80441284179688\n",
      "  model = cd_fast.enet_coordinate_descent_multi_task(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:518: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 425.6953430175781, tolerance: 231.80441284179688\n",
      "  model = cd_fast.enet_coordinate_descent_multi_task(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:518: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 571.4891357421875, tolerance: 231.80441284179688\n",
      "  model = cd_fast.enet_coordinate_descent_multi_task(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:518: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 763.46240234375, tolerance: 231.80441284179688\n",
      "  model = cd_fast.enet_coordinate_descent_multi_task(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:518: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 920.0839233398438, tolerance: 231.80441284179688\n",
      "  model = cd_fast.enet_coordinate_descent_multi_task(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/72/k144hg1s1bl5jf6b4jqxr8zw0000gn/T/ipykernel_27113/224227762.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Apply MultiTaskLasso regularization with cross-validation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mlasso\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMultiTaskLassoCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Adjust the number of CV folds as needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mlasso\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures_scaled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# Select top 30 features based on Lasso coefficients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m   1311\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mthis_l1_ratio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthis_alphas\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml1_ratios\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malphas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1312\u001b[0m                 for train, test in folds)\n\u001b[0;32m-> 1313\u001b[0;31m         mse_paths = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n\u001b[0m\u001b[1;32m   1314\u001b[0m                              **_joblib_parallel_args(prefer=\"threads\"))(jobs)\n\u001b[1;32m   1315\u001b[0m         \u001b[0mmse_paths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmse_paths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mn_l1_ratio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1041\u001b[0m             \u001b[0;31m# remaining jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1043\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1044\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1045\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    859\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    860\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 861\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    862\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    863\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    777\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py\u001b[0m in \u001b[0;36m_path_residuals\u001b[0;34m(X, y, train, test, path, path_params, alphas, l1_ratio, X_order, dtype)\u001b[0m\n\u001b[1;32m   1124\u001b[0m     X_train = check_array(X_train, accept_sparse='csc', dtype=dtype,\n\u001b[1;32m   1125\u001b[0m                           order=X_order)\n\u001b[0;32m-> 1126\u001b[0;31m     \u001b[0malphas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoefs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpath_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1127\u001b[0m     \u001b[0;32mdel\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py\u001b[0m in \u001b[0;36mlasso_path\u001b[0;34m(X, y, eps, n_alphas, alphas, precompute, Xy, copy_X, coef_init, verbose, return_n_iter, positive, **params)\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecomposition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse_encode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m     \"\"\"\n\u001b[0;32m--> 311\u001b[0;31m     return enet_path(X, y, l1_ratio=1., eps=eps, n_alphas=n_alphas,\n\u001b[0m\u001b[1;32m    312\u001b[0m                      \u001b[0malphas\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malphas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecompute\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprecompute\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mXy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m                      \u001b[0mcopy_X\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoef_init\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcoef_init\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py\u001b[0m in \u001b[0;36menet_path\u001b[0;34m(X, y, l1_ratio, eps, n_alphas, alphas, precompute, Xy, copy_X, coef_init, verbose, return_n_iter, positive, check_input, **params)\u001b[0m\n\u001b[1;32m    516\u001b[0m                 max_iter, tol, rng, random, positive)\n\u001b[1;32m    517\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 518\u001b[0;31m             model = cd_fast.enet_coordinate_descent_multi_task(\n\u001b[0m\u001b[1;32m    519\u001b[0m                 coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random)\n\u001b[1;32m    520\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprecompute\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32msklearn/linear_model/_cd_fast.pyx\u001b[0m in \u001b[0;36msklearn.linear_model._cd_fast.enet_coordinate_descent_multi_task\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import MultiTaskLassoCV\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "# Scale the feature data\n",
    "scaler = StandardScaler()\n",
    "features_scaled = scaler.fit_transform(features)\n",
    "\n",
    "# Apply MultiTaskLasso regularization with cross-validation\n",
    "lasso = MultiTaskLassoCV(cv=5, random_state=42)  # Adjust the number of CV folds as needed\n",
    "lasso.fit(features_scaled, labels)\n",
    "\n",
    "# Select top 30 features based on Lasso coefficients\n",
    "feature_selector = SelectFromModel(lasso, max_features=30)\n",
    "selected_features = feature_selector.fit_transform(features_scaled, labels)\n",
    "\n",
    "# Get the indices of the selected features\n",
    "selected_feature_indices = feature_selector.get_support(indices=True)\n",
    "\n",
    "# Get the names of the selected features\n",
    "selected_feature_names = features.columns[selected_feature_indices]\n",
    "\n",
    "# Print the selected feature names\n",
    "print(\"Selected Features:\")\n",
    "print(selected_feature_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "z5CyeIgfEsQl",
   "metadata": {
    "id": "z5CyeIgfEsQl"
   },
   "source": [
    "<h3 style=\"color:rgb(0,120,170)\">Select K Best</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "Uwcu5-EZEh7A",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 74
    },
    "id": "Uwcu5-EZEh7A",
    "outputId": "6d03f57a-c78c-47ac-bc88-b8384261b287"
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/72/k144hg1s1bl5jf6b4jqxr8zw0000gn/T/ipykernel_27113/579484064.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Perform k-fold cross-validation on the selected features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mrfc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrfc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_selected\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# Train the model on the selected features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    443\u001b[0m     \u001b[0mscorer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_scoring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 445\u001b[0;31m     cv_results = cross_validate(estimator=estimator, X=X, y=y, groups=groups,\n\u001b[0m\u001b[1;32m    446\u001b[0m                                 \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'score'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m                                 \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    248\u001b[0m     parallel = Parallel(n_jobs=n_jobs, verbose=verbose,\n\u001b[1;32m    249\u001b[0m                         pre_dispatch=pre_dispatch)\n\u001b[0;32m--> 250\u001b[0;31m     results = parallel(\n\u001b[0m\u001b[1;32m    251\u001b[0m         delayed(_fit_and_score)(\n\u001b[1;32m    252\u001b[0m             \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscorers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1044\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1045\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1046\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1047\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1048\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    859\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    860\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 861\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    862\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    863\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    777\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    596\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    599\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    385\u001b[0m             \u001b[0;31m# parallel_backend contexts set at a higher level,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m             \u001b[0;31m# since correctness does not rely on using threads.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m             trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n\u001b[0m\u001b[1;32m    388\u001b[0m                              \u001b[0;34m**\u001b[0m\u001b[0m_joblib_parallel_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'threads'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m                 delayed(_parallel_build_trees)(\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1044\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1045\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1046\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1047\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1048\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    859\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    860\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 861\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    862\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    863\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    777\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[1;32m    167\u001b[0m                                                         indices=indices)\n\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    901\u001b[0m         \"\"\"\n\u001b[1;32m    902\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 903\u001b[0;31m         super().fit(\n\u001b[0m\u001b[1;32m    904\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    905\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    392\u001b[0m                                            min_impurity_split)\n\u001b[1;32m    393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Select a subset of features using mutual information\n",
    "selector = SelectKBest(mutual_info_classif, k=50)\n",
    "X_selected = selector.fit_transform(features_pca, labels.iloc[:, 0])\n",
    "\n",
    "# Perform k-fold cross-validation on the selected features\n",
    "rfc = RandomForestClassifier()\n",
    "scores = cross_val_score(rfc, X_selected, labels.iloc[:, 0], cv=5)\n",
    "\n",
    "# Train the model on the selected features\n",
    "rfc.fit(X_selected, labels.iloc[:, 0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "OBA2p4K9YOkO",
   "metadata": {
    "id": "OBA2p4K9YOkO"
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/72/k144hg1s1bl5jf6b4jqxr8zw0000gn/T/ipykernel_27113/2390351303.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# Perform RandomizedSearchCV with cross-validation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mrandom_search\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomizedSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrfc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_distributions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparam_dist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mrandom_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    839\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 841\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    842\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    843\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1631\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1632\u001b[0m         \u001b[0;34m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1633\u001b[0;31m         evaluate_candidates(ParameterSampler(\n\u001b[0m\u001b[1;32m   1634\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_distributions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1635\u001b[0m             random_state=self.random_state))\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    793\u001b[0m                               n_splits, n_candidates, n_candidates * n_splits))\n\u001b[1;32m    794\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 795\u001b[0;31m                 out = parallel(delayed(_fit_and_score)(clone(base_estimator),\n\u001b[0m\u001b[1;32m    796\u001b[0m                                                        \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m                                                        \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1044\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1045\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1046\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1047\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1048\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    859\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    860\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 861\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    862\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    863\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    777\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    596\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    599\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    385\u001b[0m             \u001b[0;31m# parallel_backend contexts set at a higher level,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m             \u001b[0;31m# since correctness does not rely on using threads.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m             trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n\u001b[0m\u001b[1;32m    388\u001b[0m                              \u001b[0;34m**\u001b[0m\u001b[0m_joblib_parallel_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'threads'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m                 delayed(_parallel_build_trees)(\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1044\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1045\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1046\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1047\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1048\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    859\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    860\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 861\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    862\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    863\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    777\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[1;32m    167\u001b[0m                                                         indices=indices)\n\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    901\u001b[0m         \"\"\"\n\u001b[1;32m    902\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 903\u001b[0;31m         super().fit(\n\u001b[0m\u001b[1;32m    904\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    905\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    392\u001b[0m                                            min_impurity_split)\n\u001b[1;32m    393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import StratifiedKFold, RandomizedSearchCV\n",
    "from scipy.stats import randint\n",
    "\n",
    "# Initialize the Random Forest classifier\n",
    "rfc = RandomForestClassifier()\n",
    "\n",
    "\n",
    "# Perform RandomizedSearchCV with cross-validation\n",
    "random_search = RandomizedSearchCV(estimator=rfc, param_distributions=param_dist, n_iter=10, cv=skf)\n",
    "random_search.fit(X_train,  y_train.values.ravel())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "2f89b3b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Variance Explained: 0.99997836\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "# Initialize the TruncatedSVD model\n",
    "svd = TruncatedSVD(n_components=10, random_state=42)\n",
    "\n",
    "# Fit and transform the features\n",
    "features_svd = svd.fit_transform(features)\n",
    "\n",
    "# Access the explained variance ratio\n",
    "explained_variance_ratio = svd.explained_variance_ratio_\n",
    "\n",
    "# Summarize the explained variance ratio\n",
    "total_variance = np.sum(explained_variance_ratio)\n",
    "print(\"Total Variance Explained:\", total_variance)\n",
    "\n",
    "# Plot the explained variance ratio\n",
    "plt.bar(range(1, len(explained_variance_ratio) + 1), explained_variance_ratio)\n",
    "plt.xlabel('SVD Component')\n",
    "plt.ylabel('Explained Variance Ratio')\n",
    "plt.title('Explained Variance Ratio by SVD Component')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c882b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import KernelPCA\n",
    "\n",
    "# Initialize the Kernel PCA model\n",
    "kpca = KernelPCA(n_components=50, kernel='rbf', random_state=42)\n",
    "\n",
    "# Fit and transform the features\n",
    "features_kpca = kpca.fit_transform(features)\n",
    "\n",
    "# Plot the reduced features\n",
    "plt.scatter(features_kpca[:, 0], features_kpca[:, 1])\n",
    "plt.xlabel('Kernel PCA Component 1')\n",
    "plt.ylabel('Kernel PCA Component 2')\n",
    "plt.title('Kernel PCA Dimensionality Reduction')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "dRtUA4FRnQRG",
   "metadata": {
    "id": "dRtUA4FRnQRG"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log-Likelihood: -121.60146832550492\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import FactorAnalysis\n",
    "\n",
    "# instantiate the FA model with 10 components\n",
    "fa = FactorAnalysis(n_components=10)\n",
    "\n",
    "# fit the model to the data\n",
    "features_fa = fa.fit_transform(features)\n",
    "\n",
    "# calculate the log-likelihood\n",
    "log_likelihood = fa.score(features)\n",
    "\n",
    "print(\"Log-Likelihood:\", log_likelihood)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0eaf07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap.umap_ as umap\n",
    "\n",
    "# Initialize the UMAP model\n",
    "umap_model = umap.UMAP(n_components=2, random_state=42)\n",
    "\n",
    "# Fit and transform the features\n",
    "features_umap = umap_model.fit_transform(features)\n",
    "\n",
    "# Plot the reduced features\n",
    "plt.scatter(features_umap[:, 0], features_umap[:, 1])\n",
    "plt.xlabel('UMAP Component 1')\n",
    "plt.ylabel('UMAP Component 2')\n",
    "plt.title('UMAP Dimensionality Reduction')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf76a6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_tsne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4199ed2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.824011</td>\n",
       "      <td>4.989586</td>\n",
       "      <td>2.048109</td>\n",
       "      <td>-1.127897</td>\n",
       "      <td>-1.050444</td>\n",
       "      <td>-0.557161</td>\n",
       "      <td>3.819138</td>\n",
       "      <td>0.332511</td>\n",
       "      <td>6.478419</td>\n",
       "      <td>1.172503</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.590977</td>\n",
       "      <td>0.499675</td>\n",
       "      <td>-2.526777</td>\n",
       "      <td>-2.307188</td>\n",
       "      <td>-5.563121</td>\n",
       "      <td>-0.073028</td>\n",
       "      <td>-3.118582</td>\n",
       "      <td>4.099513</td>\n",
       "      <td>-3.371219</td>\n",
       "      <td>-8.057709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.561794</td>\n",
       "      <td>0.312246</td>\n",
       "      <td>-0.262711</td>\n",
       "      <td>2.155216</td>\n",
       "      <td>1.102023</td>\n",
       "      <td>-0.844087</td>\n",
       "      <td>0.207182</td>\n",
       "      <td>0.618179</td>\n",
       "      <td>-0.498371</td>\n",
       "      <td>-1.567220</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.430059</td>\n",
       "      <td>-1.390435</td>\n",
       "      <td>-1.418179</td>\n",
       "      <td>-0.310671</td>\n",
       "      <td>-2.078168</td>\n",
       "      <td>-3.029981</td>\n",
       "      <td>-2.926148</td>\n",
       "      <td>-0.152486</td>\n",
       "      <td>-0.102661</td>\n",
       "      <td>-3.313775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.733184</td>\n",
       "      <td>-0.684289</td>\n",
       "      <td>1.607968</td>\n",
       "      <td>0.487087</td>\n",
       "      <td>-0.471364</td>\n",
       "      <td>-4.204385</td>\n",
       "      <td>2.525116</td>\n",
       "      <td>-3.277972</td>\n",
       "      <td>1.256320</td>\n",
       "      <td>-0.596611</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.169866</td>\n",
       "      <td>0.212812</td>\n",
       "      <td>-0.355254</td>\n",
       "      <td>2.025556</td>\n",
       "      <td>-2.555358</td>\n",
       "      <td>-3.815025</td>\n",
       "      <td>1.403534</td>\n",
       "      <td>2.717246</td>\n",
       "      <td>-0.392710</td>\n",
       "      <td>1.935458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.111943</td>\n",
       "      <td>0.644139</td>\n",
       "      <td>1.560726</td>\n",
       "      <td>-1.066398</td>\n",
       "      <td>1.699141</td>\n",
       "      <td>-1.524472</td>\n",
       "      <td>-4.174601</td>\n",
       "      <td>-0.095782</td>\n",
       "      <td>-0.392790</td>\n",
       "      <td>-1.409440</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.599592</td>\n",
       "      <td>0.537150</td>\n",
       "      <td>-2.334193</td>\n",
       "      <td>-1.909743</td>\n",
       "      <td>-2.196267</td>\n",
       "      <td>-0.400964</td>\n",
       "      <td>-2.165187</td>\n",
       "      <td>0.568134</td>\n",
       "      <td>-1.048086</td>\n",
       "      <td>0.389139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.307290</td>\n",
       "      <td>0.419701</td>\n",
       "      <td>0.900344</td>\n",
       "      <td>-0.535825</td>\n",
       "      <td>2.727572</td>\n",
       "      <td>-0.149065</td>\n",
       "      <td>-0.368072</td>\n",
       "      <td>-2.783740</td>\n",
       "      <td>0.442479</td>\n",
       "      <td>0.465549</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.259808</td>\n",
       "      <td>1.381557</td>\n",
       "      <td>1.277140</td>\n",
       "      <td>0.297213</td>\n",
       "      <td>-1.465069</td>\n",
       "      <td>-2.089872</td>\n",
       "      <td>-0.315943</td>\n",
       "      <td>-2.510521</td>\n",
       "      <td>-0.000818</td>\n",
       "      <td>-0.226698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119995</th>\n",
       "      <td>3.653260</td>\n",
       "      <td>-2.156365</td>\n",
       "      <td>2.658804</td>\n",
       "      <td>1.139102</td>\n",
       "      <td>0.853549</td>\n",
       "      <td>-2.962768</td>\n",
       "      <td>-1.945712</td>\n",
       "      <td>1.402711</td>\n",
       "      <td>3.270103</td>\n",
       "      <td>0.989202</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.116643</td>\n",
       "      <td>1.950156</td>\n",
       "      <td>8.028561</td>\n",
       "      <td>-0.460359</td>\n",
       "      <td>0.571515</td>\n",
       "      <td>0.548930</td>\n",
       "      <td>-0.800388</td>\n",
       "      <td>-3.092847</td>\n",
       "      <td>-0.382364</td>\n",
       "      <td>2.298564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119996</th>\n",
       "      <td>0.409026</td>\n",
       "      <td>-2.087253</td>\n",
       "      <td>1.060917</td>\n",
       "      <td>0.591415</td>\n",
       "      <td>-0.375828</td>\n",
       "      <td>-1.589175</td>\n",
       "      <td>-1.542119</td>\n",
       "      <td>1.115580</td>\n",
       "      <td>1.413474</td>\n",
       "      <td>-0.747634</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.519267</td>\n",
       "      <td>2.617866</td>\n",
       "      <td>3.054711</td>\n",
       "      <td>1.748132</td>\n",
       "      <td>-0.113744</td>\n",
       "      <td>-2.344463</td>\n",
       "      <td>-2.555214</td>\n",
       "      <td>-0.821668</td>\n",
       "      <td>0.027041</td>\n",
       "      <td>0.891881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119997</th>\n",
       "      <td>-1.594115</td>\n",
       "      <td>-2.686506</td>\n",
       "      <td>1.298713</td>\n",
       "      <td>-0.085870</td>\n",
       "      <td>2.343347</td>\n",
       "      <td>-3.725334</td>\n",
       "      <td>2.174742</td>\n",
       "      <td>-0.949613</td>\n",
       "      <td>-0.204778</td>\n",
       "      <td>0.852731</td>\n",
       "      <td>...</td>\n",
       "      <td>1.854642</td>\n",
       "      <td>1.677346</td>\n",
       "      <td>1.629484</td>\n",
       "      <td>0.244122</td>\n",
       "      <td>-1.888885</td>\n",
       "      <td>-1.632606</td>\n",
       "      <td>-0.970683</td>\n",
       "      <td>2.185915</td>\n",
       "      <td>1.454292</td>\n",
       "      <td>0.568093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119998</th>\n",
       "      <td>-0.967708</td>\n",
       "      <td>-1.417340</td>\n",
       "      <td>2.276247</td>\n",
       "      <td>-0.669891</td>\n",
       "      <td>-0.799794</td>\n",
       "      <td>-1.245764</td>\n",
       "      <td>0.741048</td>\n",
       "      <td>-2.051970</td>\n",
       "      <td>2.692668</td>\n",
       "      <td>-1.229536</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.837498</td>\n",
       "      <td>1.678042</td>\n",
       "      <td>-1.379165</td>\n",
       "      <td>-0.304508</td>\n",
       "      <td>0.365879</td>\n",
       "      <td>-2.350777</td>\n",
       "      <td>-0.048141</td>\n",
       "      <td>1.396326</td>\n",
       "      <td>-1.112950</td>\n",
       "      <td>0.866010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119999</th>\n",
       "      <td>-1.157612</td>\n",
       "      <td>-3.495298</td>\n",
       "      <td>1.917524</td>\n",
       "      <td>-0.196870</td>\n",
       "      <td>-3.336174</td>\n",
       "      <td>-0.944931</td>\n",
       "      <td>-1.294846</td>\n",
       "      <td>1.428617</td>\n",
       "      <td>0.515356</td>\n",
       "      <td>1.599565</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007659</td>\n",
       "      <td>0.658827</td>\n",
       "      <td>-1.586664</td>\n",
       "      <td>-2.272094</td>\n",
       "      <td>3.790428</td>\n",
       "      <td>-3.487388</td>\n",
       "      <td>-2.032761</td>\n",
       "      <td>-0.111356</td>\n",
       "      <td>-4.042136</td>\n",
       "      <td>-0.523482</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120000 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1         2         3         4         5         6   \\\n",
       "0       3.824011  4.989586  2.048109 -1.127897 -1.050444 -0.557161  3.819138   \n",
       "1       0.561794  0.312246 -0.262711  2.155216  1.102023 -0.844087  0.207182   \n",
       "2       2.733184 -0.684289  1.607968  0.487087 -0.471364 -4.204385  2.525116   \n",
       "3      -1.111943  0.644139  1.560726 -1.066398  1.699141 -1.524472 -4.174601   \n",
       "4      -0.307290  0.419701  0.900344 -0.535825  2.727572 -0.149065 -0.368072   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "119995  3.653260 -2.156365  2.658804  1.139102  0.853549 -2.962768 -1.945712   \n",
       "119996  0.409026 -2.087253  1.060917  0.591415 -0.375828 -1.589175 -1.542119   \n",
       "119997 -1.594115 -2.686506  1.298713 -0.085870  2.343347 -3.725334  2.174742   \n",
       "119998 -0.967708 -1.417340  2.276247 -0.669891 -0.799794 -1.245764  0.741048   \n",
       "119999 -1.157612 -3.495298  1.917524 -0.196870 -3.336174 -0.944931 -1.294846   \n",
       "\n",
       "              7         8         9   ...        40        41        42  \\\n",
       "0       0.332511  6.478419  1.172503  ... -0.590977  0.499675 -2.526777   \n",
       "1       0.618179 -0.498371 -1.567220  ... -2.430059 -1.390435 -1.418179   \n",
       "2      -3.277972  1.256320 -0.596611  ... -4.169866  0.212812 -0.355254   \n",
       "3      -0.095782 -0.392790 -1.409440  ... -1.599592  0.537150 -2.334193   \n",
       "4      -2.783740  0.442479  0.465549  ... -1.259808  1.381557  1.277140   \n",
       "...          ...       ...       ...  ...       ...       ...       ...   \n",
       "119995  1.402711  3.270103  0.989202  ... -4.116643  1.950156  8.028561   \n",
       "119996  1.115580  1.413474 -0.747634  ... -1.519267  2.617866  3.054711   \n",
       "119997 -0.949613 -0.204778  0.852731  ...  1.854642  1.677346  1.629484   \n",
       "119998 -2.051970  2.692668 -1.229536  ... -1.837498  1.678042 -1.379165   \n",
       "119999  1.428617  0.515356  1.599565  ...  0.007659  0.658827 -1.586664   \n",
       "\n",
       "              43        44        45        46        47        48        49  \n",
       "0      -2.307188 -5.563121 -0.073028 -3.118582  4.099513 -3.371219 -8.057709  \n",
       "1      -0.310671 -2.078168 -3.029981 -2.926148 -0.152486 -0.102661 -3.313775  \n",
       "2       2.025556 -2.555358 -3.815025  1.403534  2.717246 -0.392710  1.935458  \n",
       "3      -1.909743 -2.196267 -0.400964 -2.165187  0.568134 -1.048086  0.389139  \n",
       "4       0.297213 -1.465069 -2.089872 -0.315943 -2.510521 -0.000818 -0.226698  \n",
       "...          ...       ...       ...       ...       ...       ...       ...  \n",
       "119995 -0.460359  0.571515  0.548930 -0.800388 -3.092847 -0.382364  2.298564  \n",
       "119996  1.748132 -0.113744 -2.344463 -2.555214 -0.821668  0.027041  0.891881  \n",
       "119997  0.244122 -1.888885 -1.632606 -0.970683  2.185915  1.454292  0.568093  \n",
       "119998 -0.304508  0.365879 -2.350777 -0.048141  1.396326 -1.112950  0.866010  \n",
       "119999 -2.272094  3.790428 -3.487388 -2.032761 -0.111356 -4.042136 -0.523482  \n",
       "\n",
       "[120000 rows x 50 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.random_projection import GaussianRandomProjection\n",
    "\n",
    "# Perform random projection to reduce the features to 50\n",
    "random_projection = GaussianRandomProjection(n_components=50, random_state=42)\n",
    "X_random_projected = random_projection.fit_transform(features_pca)\n",
    "\n",
    "# X_random_projected now contains the reduced feature representation with 50 dimensions\n",
    "ftrp =pd.DataFrame(X_random_projected)\n",
    "ftrp"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
